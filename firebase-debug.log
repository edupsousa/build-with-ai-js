[debug] [2024-05-03T17:07:37.558Z] ----------------------------------------------------------------------
[debug] [2024-05-03T17:07:37.560Z] Command:       /nix/store/c9wp3qkbfkpx2vylglrmd4w0jwvm216z-nodejs-18.20.2/bin/node /home/edupsousa/projects/build-with-ai-js/node_modules/.bin/firebase emulators:start
[debug] [2024-05-03T17:07:37.561Z] CLI Version:   13.8.0
[debug] [2024-05-03T17:07:37.561Z] Platform:      linux
[debug] [2024-05-03T17:07:37.561Z] Node Version:  v18.20.2
[debug] [2024-05-03T17:07:37.561Z] Time:          Fri May 03 2024 14:07:37 GMT-0300 (Brasilia Standard Time)
[debug] [2024-05-03T17:07:37.561Z] ----------------------------------------------------------------------
[debug] 
[debug] [2024-05-03T17:07:37.682Z] Object ".extensions" in "firebase.json" has unknown property: {"additionalProperty":"firestore-multimodal-genai"}
[debug] [2024-05-03T17:07:37.686Z] > command requires scopes: ["email","openid","https://www.googleapis.com/auth/cloudplatformprojects.readonly","https://www.googleapis.com/auth/firebase","https://www.googleapis.com/auth/cloud-platform"]
[debug] [2024-05-03T17:07:37.686Z] > authorizing via signed-in user (edupsousa@gmail.com)
[debug] [2024-05-03T17:07:37.720Z] openjdk version "21" 2023-09-19
OpenJDK Runtime Environment (build 21+35-nixos)

[debug] [2024-05-03T17:07:37.720Z] OpenJDK 64-Bit Server VM (build 21+35-nixos, mixed mode, sharing)

[debug] [2024-05-03T17:07:37.726Z] Parsed Java major version: 21
[info] i  emulators: Starting emulators: auth, functions, firestore, hosting, extensions {"metadata":{"emulator":{"name":"hub"},"message":"Starting emulators: auth, functions, firestore, hosting, extensions"}}
[debug] [2024-05-03T17:07:37.728Z] > refreshing access token with scopes: []
[debug] [2024-05-03T17:07:37.730Z] >>> [apiv2][query] POST https://www.googleapis.com/oauth2/v3/token [none]
[debug] [2024-05-03T17:07:37.730Z] >>> [apiv2][body] POST https://www.googleapis.com/oauth2/v3/token [omitted]
[debug] [2024-05-03T17:07:38.116Z] <<< [apiv2][status] POST https://www.googleapis.com/oauth2/v3/token 200
[debug] [2024-05-03T17:07:38.116Z] <<< [apiv2][body] POST https://www.googleapis.com/oauth2/v3/token [omitted]
[debug] [2024-05-03T17:07:38.143Z] >>> [apiv2][query] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js [none]
[debug] [2024-05-03T17:07:38.699Z] <<< [apiv2][status] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js 200
[debug] [2024-05-03T17:07:38.700Z] <<< [apiv2][body] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js {"projectId":"build-with-ai-js","projectNumber":"526849588450","displayName":"build-with-ai-js","name":"projects/build-with-ai-js","resources":{"hostingSite":"build-with-ai-js"},"state":"ACTIVE","etag":"1_e4b279f8-da98-4aa3-98bb-56253b503885"}
[debug] [2024-05-03T17:07:38.701Z] Successfully read params from firestore-multimodal-genai.env
[debug] [2024-05-03T17:07:38.701Z] Error: ENOENT: no such file or directory, open '/home/edupsousa/projects/build-with-ai-js/extensions/firestore-multimodal-genai.env.default'
[debug] [2024-05-03T17:07:38.701Z] Error: ENOENT: no such file or directory, open '/home/edupsousa/projects/build-with-ai-js/extensions/firestore-multimodal-genai.env.526849588450'
[debug] [2024-05-03T17:07:38.701Z] Error: ENOENT: no such file or directory, open '/home/edupsousa/projects/build-with-ai-js/extensions/firestore-multimodal-genai.env.build-with-ai-js'
[debug] [2024-05-03T17:07:38.702Z] Error: ENOENT: no such file or directory, open '/home/edupsousa/projects/build-with-ai-js/extensions/firestore-multimodal-genai.env.local'
[debug] [2024-05-03T17:07:38.702Z] >>> [apiv2][query] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js/adminSdkConfig [none]
[debug] [2024-05-03T17:07:39.316Z] <<< [apiv2][status] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js/adminSdkConfig 200
[debug] [2024-05-03T17:07:39.316Z] <<< [apiv2][body] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js/adminSdkConfig {"projectId":"build-with-ai-js","storageBucket":"build-with-ai-js.appspot.com"}
[debug] [2024-05-03T17:07:39.334Z] >>> [apiv2][query] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js [none]
[debug] [2024-05-03T17:07:40.238Z] <<< [apiv2][status] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js 200
[debug] [2024-05-03T17:07:40.238Z] <<< [apiv2][body] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js {"projectId":"build-with-ai-js","projectNumber":"526849588450","displayName":"build-with-ai-js","name":"projects/build-with-ai-js","resources":{"hostingSite":"build-with-ai-js"},"state":"ACTIVE","etag":"1_e4b279f8-da98-4aa3-98bb-56253b503885"}
[debug] [2024-05-03T17:07:40.241Z] >>> [apiv2][query] GET https://firebaseextensions.googleapis.com/v1beta/publishers/googlecloud/extensions/firestore-multimodal-genai/versions filter=&showPrereleases=true&pageSize=100&pageToken=
[debug] [2024-05-03T17:07:41.952Z] <<< [apiv2][status] GET https://firebaseextensions.googleapis.com/v1beta/publishers/googlecloud/extensions/firestore-multimodal-genai/versions 200
[debug] [2024-05-03T17:07:41.956Z] <<< [apiv2][body] GET https://firebaseextensions.googleapis.com/v1beta/publishers/googlecloud/extensions/firestore-multimodal-genai/versions {"extensionVersions":[{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.1","ref":"googlecloud/firestore-multimodal-genai@0.0.1","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.1","description":"Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.","roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to write to your Cloud Storage."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"eventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"Which provider of the Gemini Language models would you like to use? Google AI requires a valid API key, whereas Vertex AI will use Application Default Credentials.","required":true,"options":[{"value":"google-ai","label":"Google AI"}],"default":"google-ai"},{"param":"MODEL","label":"Language model","type":"SELECT","description":"Which language model do you want to use? Please ensure you pick a model supported by your selected provider.","required":true,"options":[{"value":"gemini-pro","label":"Gemini Pro"},{"value":"gemini-pro-vision","label":"Gemini Pro Vision"}],"default":"gemini-pro"},{"param":"API_KEY","label":"API Key (Generative AI for Developers, or Gemini)","type":"SECRET","description":"Please enter your API key for the Google AI Gemini API.","required":true},{"param":"COLLECTION_NAME","label":"Collection Path","type":"STRING","description":"Path to the Firestore collection where text will be generated.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.","required":true},{"param":"VARIABLE_FIELDS","label":"Variable fields","type":"STRING","description":"A comma separated list of fields to substitute as variables in the prompt.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"}],"preinstallContent":"This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of either the Vertex AI Model API, the Generative Language for Developers API, or the API for the new Gemini large language models. To make use of the Gemini option you provide a valid API key during installation of the extension.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want the Model API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Model API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nThis extension now supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`) or the base64-encoded string of an image. This image will then be provided as part of the prompt to Gemini Pro Vision.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project, and enabled the Generative Language API in your Google Cloud Project before installing this extension.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: ${param:COLLECTION_NAME}.\n3. Add a document to this collection. You may have specified some variables (${param:VARIABLE_FIELDS}) as part of your prompt that are meant to be substituted. Add those fields to the Firestore document, and the extension will substitute the values into the prompt before calling Google AI.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message.\n   When processing is finished, the ${param:RESPONSE_FIELD} field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n## About the models\n\nThe extension gives you a choice of 3 models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with Gemini\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.\n\n\n\n**Details**: This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of either the Vertex AI Model API, the Generative Language for Developers API, or the API for the new Gemini large language models. To make use of the Gemini option you provide a valid API key during installation of the extension.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want the Model API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Model API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nThis extension now supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`) or the base64-encoded string of an image. This image will then be provided as part of the prompt to Gemini Pro Vision.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project, and enabled the Generative Language API in your Google Cloud Project before installing this extension.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: Which provider of the Gemini Language models would you like to use? Google AI requires a valid API key, whereas Vertex AI will use Application Default Credentials.\n\n* Language model: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n\n* API Key (Generative AI for Developers, or Gemini): Please enter your API key for the Google AI Gemini API.\n\n* Collection Path: Path to the Firestore collection where text will be generated.\n\n* Prompt: Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.\n\n* Variable fields: A comma separated list of fields to substitute as variables in the prompt.\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to write to your Cloud Storage.)\n","displayName":"Multimodal Tasks with Gemini","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/memory","label":"Function memory","type":"SELECT","description":"How much memory should be allocated to each v1 function?","options":[{"value":"128","label":"128MB"},{"value":"256","label":"256MB"},{"value":"512","label":"512MB"},{"value":"1024","label":"1GB"},{"value":"2048","label":"2GB"},{"value":"4096","label":"4GB"},{"value":"8192","label":"8GB"}],"default":"256","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"56e72ac6f930b4ce006733488b0550fee3bb92e065289bd314bd07330eba48b5","createTime":"2023-12-15T20:55:32.170924Z","id":"0.0.1","releaseNotes":"Initial release of the firestore-multimodal-genai extension.\n","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/b77039ad7c9381e19f03a0ce608b30df90542a46","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.1@512.png","iconType":"PNG_512"}],"listing":{"state":"APPROVED"},"tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.1-rc.0","ref":"googlecloud/firestore-multimodal-genai@0.0.1-rc.0","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.1-rc.0","description":"Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.","roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to write to your Cloud Storage."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"eventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"Which provider of the Gemini Language models would you like to use? Google AI requires a valid API key, whereas Vertex AI will use Application Default Credentials.","required":true,"options":[{"value":"google-ai","label":"Google AI"}],"default":"google-ai"},{"param":"MODEL","label":"Language model","type":"SELECT","description":"Which language model do you want to use? Please ensure you pick a model supported by your selected provider.","required":true,"options":[{"value":"gemini-pro","label":"Gemini Pro"},{"value":"gemini-pro-vision","label":"Gemini Pro Vision"}],"default":"gemini-pro"},{"param":"API_KEY","label":"API Key (Generative AI for Developers, or Gemini)","type":"SECRET","description":"Please enter your API key for the Google AI Gemini API.","required":true},{"param":"COLLECTION_NAME","label":"Collection Path","type":"STRING","description":"Path to the Firestore collection where text will be generated.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.","required":true},{"param":"VARIABLE_FIELDS","label":"Variable fields","type":"STRING","description":"A comma separated list of fields to substitute as variables in the prompt.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"}],"preinstallContent":"This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of either the Vertex AI Model API, the Generative Language for Developers API, or the API for the new Gemini large language models. To make use of the Gemini option you provide a valid API key during installation of the extension.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want the Model API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Model API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nThis extension now supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`) or the base64-encoded string of an image. This image will then be provided as part of the prompt to Gemini Pro Vision.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project, and enabled the Generative Language API in your Google Cloud Project before installing this extension.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: ${param:COLLECTION_NAME}.\n3. Add a document to this collection. You may have specified some variables (${param:VARIABLE_FIELDS}) as part of your prompt that are meant to be substituted. Add those fields to the Firestore document, and the extension will substitute the values into the prompt before calling Google AI.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message.\n   When processing is finished, the ${param:RESPONSE_FIELD} field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n## About the models\n\nThe extension gives you a choice of 3 models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with Gemini\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.\n\n\n\n**Details**: This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of either the Vertex AI Model API, the Generative Language for Developers API, or the API for the new Gemini large language models. To make use of the Gemini option you provide a valid API key during installation of the extension.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want the Model API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Model API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nThis extension now supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`) or the base64-encoded string of an image. This image will then be provided as part of the prompt to Gemini Pro Vision.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project, and enabled the Generative Language API in your Google Cloud Project before installing this extension.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: Which provider of the Gemini Language models would you like to use? Google AI requires a valid API key, whereas Vertex AI will use Application Default Credentials.\n\n* Language model: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n\n* API Key (Generative AI for Developers, or Gemini): Please enter your API key for the Google AI Gemini API.\n\n* Collection Path: Path to the Firestore collection where text will be generated.\n\n* Prompt: Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.\n\n* Variable fields: A comma separated list of fields to substitute as variables in the prompt.\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to write to your Cloud Storage.)\n","displayName":"Multimodal Tasks with Gemini","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/memory","label":"Function memory","type":"SELECT","description":"How much memory should be allocated to each v1 function?","options":[{"value":"128","label":"128MB"},{"value":"256","label":"256MB"},{"value":"512","label":"512MB"},{"value":"1024","label":"1GB"},{"value":"2048","label":"2GB"},{"value":"4096","label":"4GB"},{"value":"8192","label":"8GB"}],"default":"256","advanced":true}],"tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"6402a6b5029ce49efd8a6e4013f0b154f46a08946680ea25d5fdeb866db9492d","createTime":"2023-12-14T21:15:44.662535Z","id":"0.0.1-rc.0","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/52c6d76e3572fb36211d1803e4cf0907e309e1b1","listing":{"state":"UNLISTED"},"tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.2","ref":"googlecloud/firestore-multimodal-genai@0.0.2","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.2","description":"Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.","roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to write to your Cloud Storage."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"eventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.","required":true,"options":[{"value":"google-ai","label":"Google AI"}],"default":"google-ai"},{"param":"MODEL","label":"Language model","type":"SELECT","description":"Which language model do you want to use? Please ensure you pick a model supported by your selected provider.","required":true,"options":[{"value":"gemini-pro","label":"Gemini Pro"},{"value":"gemini-pro-vision","label":"Gemini Pro Vision"}],"default":"gemini-pro"},{"param":"API_KEY","label":"API Key (Generative AI for Developers, or Gemini)","type":"SECRET","description":"Please enter your API key for the Google AI Gemini API.","required":true},{"param":"COLLECTION_NAME","label":"Collection Path","type":"STRING","description":"Path to the Firestore collection where text will be generated.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.","required":true},{"param":"VARIABLE_FIELDS","label":"Variable fields","type":"STRING","description":"A comma separated list of fields to substitute as variables in the prompt.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"}],"preinstallContent":"This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nThis extension now supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`) or the base64-encoded string of an image. This image will then be provided as part of the prompt to Gemini Pro Vision.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project, and have obtained an API key for Google AI's Gemini API.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: ${param:COLLECTION_NAME}.\n3. Add a document to this collection. You may have specified some variables (${param:VARIABLE_FIELDS}) as part of your prompt that are meant to be substituted. Add those fields to the Firestore document, and the extension will substitute the values into the prompt before calling Google AI.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message.\n   When processing is finished, the ${param:RESPONSE_FIELD} field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n## About the models\n\nThe extension gives you a choice of 3 models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with Gemini\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.\n\n\n\n**Details**: This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nThis extension now supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`) or the base64-encoded string of an image. This image will then be provided as part of the prompt to Gemini Pro Vision.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project, and have obtained an API key for Google AI's Gemini API.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.\n\n* Language model: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n\n* API Key (Generative AI for Developers, or Gemini): Please enter your API key for the Google AI Gemini API.\n\n* Collection Path: Path to the Firestore collection where text will be generated.\n\n* Prompt: Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.\n\n* Variable fields: A comma separated list of fields to substitute as variables in the prompt.\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to write to your Cloud Storage.)\n","displayName":"Multimodal Tasks with Gemini","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/memory","label":"Function memory","type":"SELECT","description":"How much memory should be allocated to each v1 function?","options":[{"value":"128","label":"128MB"},{"value":"256","label":"256MB"},{"value":"512","label":"512MB"},{"value":"1024","label":"1GB"},{"value":"2048","label":"2GB"},{"value":"4096","label":"4GB"},{"value":"8192","label":"8GB"}],"default":"256","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"50eaef44def1c600f2b557257f67efaa435679d296bb8f7104629b8807ff8e46","createTime":"2023-12-20T12:49:49.993155Z","id":"0.0.2","releaseNotes":"- Update docs to describe provider param correctly\n","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/6a84bcbe8a43726ec3041083824ba9c169c41373","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.2@512.png","iconType":"PNG_512"}],"listing":{"state":"APPROVED"},"metrics":{"activeInstallCount":"20"},"tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.3","ref":"googlecloud/firestore-multimodal-genai@0.0.3","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.3","description":"Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.","apis":[{"apiName":"generativelanguage.googleapis.com","reason":"Used to access Gemini models through the Generative Language API."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to write to your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the PaLM API via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. For Google AI you will require an API key, whereas Vertex AI will authenticate using application default credentials. For more information see the [docs](https://firebase.google.com/docs/admin/setup#initialize-sdk).","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Language model","type":"SELECT","description":"Which language model do you want to use? Please ensure you pick a model supported by your selected provider.","required":true,"options":[{"value":"gemini-pro","label":"Gemini Pro"},{"value":"gemini-pro-vision","label":"Gemini Pro Vision"}],"default":"gemini-pro"},{"param":"API_KEY","label":"API Key","type":"SECRET","description":"If you would like the extension to use an API key to access Gemini, please enter it here."},{"param":"COLLECTION_NAME","label":"Collection Path","type":"STRING","description":"Path to the Firestore collection where text will be generated.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.","required":true},{"param":"VARIABLE_FIELDS","label":"Variable fields","type":"STRING","description":"A comma separated list of fields to substitute as variables in the prompt.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"}],"preinstallContent":"This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: ${param:COLLECTION_NAME}.\n3. Add a document to this collection. You may have specified some variables (${param:VARIABLE_FIELDS}) as part of your prompt that are meant to be substituted. Add those fields to the Firestore document, and the extension will substitute the values into the prompt before calling Google AI.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message.\n   When processing is finished, the ${param:RESPONSE_FIELD} field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n## About the models\n\nThe extension gives you a choice of 3 models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nIf you have selected to use the Gemini Pro Vision model, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with Gemini\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.\n\n\n\n**Details**: This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. For Google AI you will require an API key, whereas Vertex AI will authenticate using application default credentials. For more information see the [docs](https://firebase.google.com/docs/admin/setup#initialize-sdk).\n\n* Language model: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n\n* API Key: If you would like the extension to use an API key to access Gemini, please enter it here.\n\n* Collection Path: Path to the Firestore collection where text will be generated.\n\n* Prompt: Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.\n\n* Variable fields: A comma separated list of fields to substitute as variables in the prompt.\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**APIs Used**:\n\n* generativelanguage.googleapis.com (Reason: Used to access Gemini models through the Generative Language API.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to write to your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the PaLM API via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with Gemini","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"27d15031a826cafc531b353c5464d00b75e923c4d65b07595f23e45f164abaa7","createTime":"2024-01-24T12:20:32.384580Z","id":"0.0.3","releaseNotes":"- Add Vertex AI provider\n\n- Add image compression for large image files\n","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/4bcd1f0b444f4b227ca9f99a358b6c84e3df0a75","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.3@512.png","iconType":"PNG_512"}],"listing":{"state":"APPROVED"},"metrics":{"activeInstallCount":"40"},"tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.3-rc.0","ref":"googlecloud/firestore-multimodal-genai@0.0.3-rc.0","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.3-rc.0","description":"Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.","apis":[{"apiName":"generativelanguage.googleapis.com","reason":"Used to access Gemini models through the Generative Language API."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to write to your Cloud Storage."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"eventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.","required":true,"options":[{"value":"google-ai","label":"Google AI"}],"default":"google-ai"},{"param":"MODEL","label":"Language model","type":"SELECT","description":"Which language model do you want to use? Please ensure you pick a model supported by your selected provider.","required":true,"options":[{"value":"gemini-pro","label":"Gemini Pro"},{"value":"gemini-pro-vision","label":"Gemini Pro Vision"}],"default":"gemini-pro"},{"param":"API_KEY","label":"API Key","type":"SECRET","description":"If you would like the extension to use an API key to access Gemini, please enter it here."},{"param":"COLLECTION_NAME","label":"Collection Path","type":"STRING","description":"Path to the Firestore collection where text will be generated.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.","required":true},{"param":"VARIABLE_FIELDS","label":"Variable fields","type":"STRING","description":"A comma separated list of fields to substitute as variables in the prompt.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"}],"preinstallContent":"This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nThis extension now supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`) or the base64-encoded string of an image. This image will then be provided as part of the prompt to Gemini Pro Vision.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: ${param:COLLECTION_NAME}.\n3. Add a document to this collection. You may have specified some variables (${param:VARIABLE_FIELDS}) as part of your prompt that are meant to be substituted. Add those fields to the Firestore document, and the extension will substitute the values into the prompt before calling Google AI.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message.\n   When processing is finished, the ${param:RESPONSE_FIELD} field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n## About the models\n\nThe extension gives you a choice of 3 models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with Gemini\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.\n\n\n\n**Details**: This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nThis extension now supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`) or the base64-encoded string of an image. This image will then be provided as part of the prompt to Gemini Pro Vision.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.\n\n* Language model: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n\n* API Key: If you would like the extension to use an API key to access Gemini, please enter it here.\n\n* Collection Path: Path to the Firestore collection where text will be generated.\n\n* Prompt: Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.\n\n* Variable fields: A comma separated list of fields to substitute as variables in the prompt.\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**APIs Used**:\n\n* generativelanguage.googleapis.com (Reason: Used to access Gemini models through the Generative Language API.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to write to your Cloud Storage.)\n","displayName":"Multimodal Tasks with Gemini","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/memory","label":"Function memory","type":"SELECT","description":"How much memory should be allocated to each v1 function?","options":[{"value":"128","label":"128MB"},{"value":"256","label":"256MB"},{"value":"512","label":"512MB"},{"value":"1024","label":"1GB"},{"value":"2048","label":"2GB"},{"value":"4096","label":"4GB"},{"value":"8192","label":"8GB"}],"default":"256","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"24f75ceee741dd02b579620dcec43daaf64f3125bde63623d24332c20b061a3c","createTime":"2023-12-21T12:05:57.346422Z","id":"0.0.3-rc.0","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/e32ec6e8352421886d78fd0a43ee839b9e2d43f4","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.3-rc.0@512.png","iconType":"PNG_512"}],"listing":{"state":"UNLISTED"},"tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.3-rc.1","ref":"googlecloud/firestore-multimodal-genai@0.0.3-rc.1","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.3-rc.1","description":"Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.","apis":[{"apiName":"generativelanguage.googleapis.com","reason":"Used to access Gemini models through the Generative Language API."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to write to your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the PaLM API via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. For Google AI you will require an API key, whereas Vertex AI will authenticate using application default credentials. For more information see the [docs](https://firebase.google.com/docs/admin/setup#initialize-sdk).","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Language model","type":"SELECT","description":"Which language model do you want to use? Please ensure you pick a model supported by your selected provider.","required":true,"options":[{"value":"gemini-pro","label":"Gemini Pro"},{"value":"gemini-pro-vision","label":"Gemini Pro Vision"}],"default":"gemini-pro"},{"param":"API_KEY","label":"API Key","type":"SECRET","description":"If you would like the extension to use an API key to access Gemini, please enter it here."},{"param":"COLLECTION_NAME","label":"Collection Path","type":"STRING","description":"Path to the Firestore collection where text will be generated.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.","required":true},{"param":"VARIABLE_FIELDS","label":"Variable fields","type":"STRING","description":"A comma separated list of fields to substitute as variables in the prompt.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"}],"preinstallContent":"This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: ${param:COLLECTION_NAME}.\n3. Add a document to this collection. You may have specified some variables (${param:VARIABLE_FIELDS}) as part of your prompt that are meant to be substituted. Add those fields to the Firestore document, and the extension will substitute the values into the prompt before calling Google AI.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message.\n   When processing is finished, the ${param:RESPONSE_FIELD} field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n## About the models\n\nThe extension gives you a choice of 3 models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nIf you have selected to use the Gemini Pro Vision model, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with Gemini\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.\n\n\n\n**Details**: This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. For Google AI you will require an API key, whereas Vertex AI will authenticate using application default credentials. For more information see the [docs](https://firebase.google.com/docs/admin/setup#initialize-sdk).\n\n* Language model: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n\n* API Key: If you would like the extension to use an API key to access Gemini, please enter it here.\n\n* Collection Path: Path to the Firestore collection where text will be generated.\n\n* Prompt: Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.\n\n* Variable fields: A comma separated list of fields to substitute as variables in the prompt.\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**APIs Used**:\n\n* generativelanguage.googleapis.com (Reason: Used to access Gemini models through the Generative Language API.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to write to your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the PaLM API via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with Gemini","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"476c61679866d9b593d1ef7eb8c00e9cf7e0448753de3ddd4e370727835f60a7","createTime":"2024-01-19T13:45:50.874866Z","id":"0.0.3-rc.1","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/155fbb285aa609102ebefa480a62e49871a4ded7","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.3-rc.1@512.png","iconType":"PNG_512"}],"listing":{"state":"UNLISTED"},"tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.4","ref":"googlecloud/firestore-multimodal-genai@0.0.4","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.4","description":"Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.","apis":[{"apiName":"aiplatform.googleapis.com","reason":"For access to the Vertex AI Gemini API if this provider is chosen."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to read from your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of generative models. For Google AI you will require an API key, whereas Vertex AI will authenticate using application default credentials. For more information see the [docs](https://firebase.google.com/docs/admin/setup#initialize-sdk).","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Generative model","type":"STRING","description":"Which genai model do you want to use? For Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for example models/gemini-pro should be chosen as gemini-pro). For Vertex AI, there is a list of models [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), currently only the Gemini family of models listed there is supported.","required":true,"default":"gemini-pro"},{"param":"API_KEY","label":"Google AI API Key","type":"SECRET","description":"If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used."},{"param":"COLLECTION_NAME","label":"Collection Path","type":"STRING","description":"Path to the Firestore collection where text will be generated.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc. For example if you set this parameter as \"What is the capital of {{ country }}?\"","required":true},{"param":"VARIABLE_FIELDS","label":"Variable fields","type":"STRING","description":"A comma separated list of fields to substitute as variables in the prompt.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"},{"param":"HARM_CATEGORY_HATE_SPEECH","label":"Hate Speech Threshold","type":"SELECT","description":"Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_DANGEROUS_CONTENT","label":"Dangerous Content Threshold","type":"SELECT","description":"Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_HARASSMENT","label":"Harassment Content Threshold","type":"SELECT","description":"Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_SEXUALLY_EXPLICIT","label":"Sexual Content Threshold","type":"SELECT","description":"Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}],"preinstallContent":"This extension allows you to perform generative tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of generative models. The extension supports both the Google AI and Vertex AI Gemini APIs\n- **Generative model**: Which genai model do you want to use?\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the generative task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a genai model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI,\nthere is a list of models [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: **${param:COLLECTION_NAME}**.\n3. Add a document to this collection. You may have specified some variables (${param:VARIABLE_FIELDS}) during installation, to be substituted into your prompt. Add those fields to the Firestore document, and the extension will substitute the values into the prompt before calling Google AI.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message.\n   When processing is finished, the **${param:RESPONSE_FIELD}** field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Google AI documentation](https://ai.google.dev/docs).\n\n- Vertex AI: For more details on the Vertex AI Gemini API, see the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).\n\n## About the models\n\nThe extension gives you a choice of 2 models:\n\n- Gemini Pro\n- Gemini Pro Vision\n\n#### Multimodal Prompts\n\nThe Gemini Pro Vision model accepts multimodal prompts. This extension allows for multimodal prompting using this model.\n\nOn installation you may pick an `image` field. The image field must be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nNote that Google AI requires prompts to have both an image and text part, whereas Vertex AI allows gemini-pro-vision to be prompted with text only as well. If you have selected to use the Gemini Pro Vision model and have Google AI as a provider then any document handled by the extension must contain an image field.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will attempt to compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with Gemini\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.\n\n\n\n**Details**: This extension allows you to perform generative tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of generative models. The extension supports both the Google AI and Vertex AI Gemini APIs\n- **Generative model**: Which genai model do you want to use?\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the generative task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a genai model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI,\nthere is a list of models [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of generative models. For Google AI you will require an API key, whereas Vertex AI will authenticate using application default credentials. For more information see the [docs](https://firebase.google.com/docs/admin/setup#initialize-sdk).\n\n* Generative model: Which genai model do you want to use? For Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for example models/gemini-pro should be chosen as gemini-pro). For Vertex AI, there is a list of models [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), currently only the Gemini family of models listed there is supported.\n\n* Google AI API Key: If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used.\n\n* Collection Path: Path to the Firestore collection where text will be generated.\n\n* Prompt: Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc. For example if you set this parameter as \"What is the capital of {{ country }}?\"\n\n* Variable fields: A comma separated list of fields to substitute as variables in the prompt.\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n* Hate Speech Threshold: Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.\n\n* Dangerous Content Threshold: Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.\n\n* Harassment Content Threshold: Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.\n\n* Sexual Content Threshold: Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**APIs Used**:\n\n* aiplatform.googleapis.com (Reason: For access to the Vertex AI Gemini API if this provider is chosen.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to read from your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with Gemini","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"b601900c24dff5b32302dc10ae5f35f43540a0e03b4f2010eb62b044536caa07","createTime":"2024-02-12T10:42:22.153730Z","id":"0.0.4","releaseNotes":"- Make model a string param, to allow for future changes to model names.\n\n- Update documentation\n\n- Add safety threshold params\n","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/a64c0a94bd2693ead203df64efa663b43df717b6","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.4@512.png","iconType":"PNG_512"}],"listing":{"state":"APPROVED"},"metrics":{"activeInstallCount":"10"},"tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.4-rc.0","ref":"googlecloud/firestore-multimodal-genai@0.0.4-rc.0","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.4-rc.0","description":"Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.","apis":[{"apiName":"generativelanguage.googleapis.com","reason":"Used to access Gemini models through the Generative Language API."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to write to your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the PaLM API via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. For Google AI you will require an API key, whereas Vertex AI will authenticate using application default credentials. For more information see the [docs](https://firebase.google.com/docs/admin/setup#initialize-sdk).","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Language model","type":"SELECT","description":"Which language model do you want to use? Please ensure you pick a model supported by your selected provider.","required":true,"options":[{"value":"gemini-pro","label":"Gemini Pro"},{"value":"gemini-pro-vision","label":"Gemini Pro Vision"}],"default":"gemini-pro"},{"param":"API_KEY","label":"API Key","type":"SECRET","description":"If you would like the extension to use an API key to access Gemini, please enter it here."},{"param":"COLLECTION_NAME","label":"Collection Path","type":"STRING","description":"Path to the Firestore collection where text will be generated.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.","required":true},{"param":"VARIABLE_FIELDS","label":"Variable fields","type":"STRING","description":"A comma separated list of fields to substitute as variables in the prompt.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"}],"preinstallContent":"This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: ${param:COLLECTION_NAME}.\n3. Add a document to this collection. You may have specified some variables (${param:VARIABLE_FIELDS}) as part of your prompt that are meant to be substituted. Add those fields to the Firestore document, and the extension will substitute the values into the prompt before calling Google AI.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message.\n   When processing is finished, the ${param:RESPONSE_FIELD} field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n## About the models\n\nThe extension gives you a choice of 3 models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nIf you have selected to use the Gemini Pro Vision model, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with Gemini\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.\n\n\n\n**Details**: This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini)\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. For Google AI you will require an API key, whereas Vertex AI will authenticate using application default credentials. For more information see the [docs](https://firebase.google.com/docs/admin/setup#initialize-sdk).\n\n* Language model: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n\n* API Key: If you would like the extension to use an API key to access Gemini, please enter it here.\n\n* Collection Path: Path to the Firestore collection where text will be generated.\n\n* Prompt: Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.\n\n* Variable fields: A comma separated list of fields to substitute as variables in the prompt.\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**APIs Used**:\n\n* generativelanguage.googleapis.com (Reason: Used to access Gemini models through the Generative Language API.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to write to your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the PaLM API via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with Gemini","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"0c8c37d931d12b3e58b11ce6f9f4c96af40fdbc5b6271e82b79edce4a435358b","createTime":"2024-01-25T12:50:56.825709Z","id":"0.0.4-rc.0","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/c4a6a10dfb3cf0ad22f65b2e6d42337cb3d6c385","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.4-rc.0@512.png","iconType":"PNG_512"}],"listing":{"state":"UNLISTED"},"tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.4-rc.1","ref":"googlecloud/firestore-multimodal-genai@0.0.4-rc.1","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.4-rc.1","description":"Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.","apis":[{"apiName":"generativelanguage.googleapis.com","reason":"Used to access Gemini models through the Generative Language API."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to write to your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the PaLM API via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. For Google AI you will require an API key, whereas Vertex AI will authenticate using application default credentials. For more information see the [docs](https://firebase.google.com/docs/admin/setup#initialize-sdk).","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Language model","type":"SELECT","description":"Which language model do you want to use? Please ensure you pick a model supported by your selected provider.","required":true,"options":[{"value":"gemini-pro","label":"Gemini Pro"},{"value":"gemini-pro-vision","label":"Gemini Pro Vision"}],"default":"gemini-pro"},{"param":"API_KEY","label":"API Key","type":"SECRET","description":"If you would like the extension to use an API key to access Gemini, please enter it here."},{"param":"COLLECTION_NAME","label":"Collection Path","type":"STRING","description":"Path to the Firestore collection where text will be generated.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.","required":true},{"param":"VARIABLE_FIELDS","label":"Variable fields","type":"STRING","description":"A comma separated list of fields to substitute as variables in the prompt.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"},{"param":"RAG_HOOK_URL","label":"Custom RAG Hook URL","type":"STRING","description":"If provided, this extension will attempt to fetch data from this URL. The endpoint provided must return a json body. The extension will extract any string properties from this body and attempt to substitute them as handlebar variables into the extension prompt. The extension will pass in the Custom Hook API Key parameter into the headers object as x-api-key.","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"RAG_HOOK_INPUT_FIELDS","label":"RAG Hook Input Variable Fields","type":"STRING","description":"A comma separated list of fields to pass in the body of the RAG request, if the RAG Hook URL is specified.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RAG_HOOK_OUTPUT_FIELDS","label":"RAG hook output variable fields","type":"STRING","description":"A comma separated list of fields to be extracted from the RAG response body, if the RAG Hook URL is specified.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RAG_HOOK_API_KEY","label":"Custom RAG Hook API Key","type":"SECRET","description":"If you have provided a Custom Hook URL which needs authentication, provide an API key secret here. It will be passed into custom hook request headers under x-api-key."}],"preinstallContent":"This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini) multimodal prompt model\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n### Custom RAG Hook\n\nIf you specify a a RAG (Retrieval Augmentation Generation) hook URL during installation, the extension will call this endpoint to obtain additional data for the prompt. You may specify an API key for your hook, which will be passed in the `x-api-key` header. You should also specify input and output fields for the RAG hook, as comma separated lists.\n\nThe input fields will be extracted from the document and passed in the body of the request to the RAG endpoint, whereas the response body will be filtered for the output fields, and these will be made available as handlebars variables when the extension creates the prompt for Gemini.\n\n#### Example\n\nSuppose we configure the extension with `RAG_HOOK_URL=https://movieAPI.com/search`, `RAG_HOOK_INPUT_FIELDS=query` and `RAG_HOOK_OUTPUT_FIELDS=searchResult`, and our prompt is `PROMPT=Tell about the following actors in this movie {{searchResult}}`.\n\nThe extension will call the RAG hook, extract the string `searchResult` from the JSON body of the response, and substitute it into the prompt it later calls Gemini with.\n\nThis can be combined with the existing substitution directly from firestore document fields.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: **${param:COLLECTION_NAME}**.\n3. Add a document to this collection. You may have specified some variables (${param:VARIABLE_FIELDS}) during installation, to be substituted into your prompt. Add those fields to the Firestore document, and the extension will substitute the values into the prompt before calling Google AI.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message.\n   When processing is finished, the **${param:RESPONSE_FIELD}** field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n- Vertex AI: For more details on the Vertex AI Gemini API, see the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).\n\n## About the models\n\nThe extension gives you a choice of 3 models:\n\n- Gemini Pro\n- Gemini Pro Vision\n\n#### Multimodal Prompts\n\nIf you have selected to use the Gemini Pro Vision model, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with Gemini\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.\n\n\n\n**Details**: This extension allows you to perform language tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of large language models. Currently the extension only supports the Google AI API (for developers) but in future will support the Vertex AI Gemini API.\n- **Language model**: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the language task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a language model\n\nThis extension supports the following language models:\n\n- [Gemini Pro](https://ai.google.dev/models/gemini) text model\n- [Gemini Pro Vision](https://ai.google.dev/models/gemini) multimodal prompt model\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n### Custom RAG Hook\n\nIf you specify a a RAG (Retrieval Augmentation Generation) hook URL during installation, the extension will call this endpoint to obtain additional data for the prompt. You may specify an API key for your hook, which will be passed in the `x-api-key` header. You should also specify input and output fields for the RAG hook, as comma separated lists.\n\nThe input fields will be extracted from the document and passed in the body of the request to the RAG endpoint, whereas the response body will be filtered for the output fields, and these will be made available as handlebars variables when the extension creates the prompt for Gemini.\n\n#### Example\n\nSuppose we configure the extension with `RAG_HOOK_URL=https://movieAPI.com/search`, `RAG_HOOK_INPUT_FIELDS=query` and `RAG_HOOK_OUTPUT_FIELDS=searchResult`, and our prompt is `PROMPT=Tell about the following actors in this movie {{searchResult}}`.\n\nThe extension will call the RAG hook, extract the string `searchResult` from the JSON body of the respons, and substitute it into the prompt it later calls Gemini with.\n\nThis can be combined with the existing substitution directly from firestore document fields.\n\n## Additional Setup\n\nEnsure you have a [Cloud Firestore database](https://firebase.google.com/docs/firestore/quickstart) set up in your Firebase project.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\nAdditionally, this extension uses the Google AI Gemini API. For more details on this Gemini API, see the [Gemini homepage](https://ai.google.dev/docs).\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. For Google AI you will require an API key, whereas Vertex AI will authenticate using application default credentials. For more information see the [docs](https://firebase.google.com/docs/admin/setup#initialize-sdk).\n\n* Language model: Which language model do you want to use? Please ensure you pick a model supported by your selected provider.\n\n* API Key: If you would like the extension to use an API key to access Gemini, please enter it here.\n\n* Collection Path: Path to the Firestore collection where text will be generated.\n\n* Prompt: Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc.\n\n* Variable fields: A comma separated list of fields to substitute as variables in the prompt.\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n* Custom RAG Hook URL: If provided, this extension will attempt to fetch data from this URL. The endpoint provided must return a json body. The extension will extract any string properties from this body and attempt to substitute them as handlebar variables into the extension prompt. The extension will pass in the Custom Hook API Key parameter into the headers object as x-api-key.\n\n* RAG Hook Input Variable Fields: A comma separated list of fields to pass in the body of the RAG request, if the RAG Hook URL is specified.\n\n* RAG hook output variable fields: A comma separated list of fields to be extracted from the RAG response body, if the RAG Hook URL is specified.\n\n* Custom RAG Hook API Key: If you have provided a Custom Hook URL which needs authentication, provide an API key secret here. It will be passed into custom hook request headers under x-api-key.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**APIs Used**:\n\n* generativelanguage.googleapis.com (Reason: Used to access Gemini models through the Generative Language API.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to write to your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the PaLM API via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with Gemini","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"fcb3e9508ff688dae0828825b2832945dadc30e2438f186df66d8cdbaf104b97","createTime":"2024-02-06T16:39:58.581447Z","id":"0.0.4-rc.1","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/6df125b69afd6ef2295acaf5047bf4592ff65e57","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.4-rc.1@512.png","iconType":"PNG_512"}],"listing":{"state":"UNLISTED"},"tags":["ai","generative-ai","text-ai","language-ai","large-language-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.4-rc.2","ref":"googlecloud/firestore-multimodal-genai@0.0.4-rc.2","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.4-rc.2","description":"Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.","apis":[{"apiName":"aiplatform.googleapis.com","reason":"For access to the Vertex AI Gemini API if this provider is chosen."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to read from your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of generative models. For Google AI you will require an API key, whereas Vertex AI will authenticate using application default credentials. For more information see the [docs](https://firebase.google.com/docs/admin/setup#initialize-sdk).","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Generative model","type":"STRING","description":"Which genai model do you want to use? For Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for example models/gemini-pro should be chosen as gemini-pro). For Vertex AI, there is a list of models [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).","required":true,"default":"gemini-pro"},{"param":"API_KEY","label":"Google AI API Key","type":"SECRET","description":"If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used."},{"param":"COLLECTION_NAME","label":"Collection Path","type":"STRING","description":"Path to the Firestore collection where text will be generated.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc. For example if you set this parameter as \"What is the capital of {{ country }}?\"","required":true},{"param":"VARIABLE_FIELDS","label":"Variable fields","type":"STRING","description":"A comma separated list of fields to substitute as variables in the prompt.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"},{"param":"HARM_CATEGORY_HATE_SPEECH","label":"Hate Speech Threshold","type":"SELECT","description":"Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_DANGEROUS_CONTENT","label":"Dangerous Content Threshold","type":"SELECT","description":"Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_HARASSMENT","label":"Harassment Content Threshold","type":"SELECT","description":"Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_SEXUALLY_EXPLICIT","label":"Sexual Content Threshold","type":"SELECT","description":"Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}],"preinstallContent":"This extension allows you to perform generative tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of generative models. The extension supports both the Google AI and Vertex AI Gemini APIs\n- **Generative model**: Which genai model do you want to use?\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the generative task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a genai model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI,\nthere is a list of models [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: **${param:COLLECTION_NAME}**.\n3. Add a document to this collection. You may have specified some variables (${param:VARIABLE_FIELDS}) during installation, to be substituted into your prompt. Add those fields to the Firestore document, and the extension will substitute the values into the prompt before calling Google AI.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message.\n   When processing is finished, the **${param:RESPONSE_FIELD}** field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Google AI documentation](https://ai.google.dev/docs).\n\n- Vertex AI: For more details on the Vertex AI Gemini API, see the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).\n\n## About the models\n\nThe extension gives you a choice of 2 models:\n\n- Gemini Pro\n- Gemini Pro Vision\n\n#### Multimodal Prompts\n\nThe Gemini Pro Vision model accepts multimodal prompts. This extension allows for multimodal prompting using this model.\n\nOn installation you may pick an `image` field. The image field must be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nNote that Google AI requires prompts to have both an image and text part, whereas Vertex AI allows gemini-pro-vision to be prompted with text only as well. If you have selected to use the Gemini Pro Vision model and have Google AI as a provider then any document handled by the extension must contain an image field.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will attempt to compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with Gemini\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs AI/ML tasks on text and images, customizable with prompt engineering, using Gemini AI and Firestore.\n\n\n\n**Details**: This extension allows you to perform generative tasks using Google AI, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Generative AI Provider** This extension makes use of the Gemini family of generative models. The extension supports both the Google AI and Vertex AI Gemini APIs\n- **Generative model**: Which genai model do you want to use?\n- **Prompt:** This is the text that you want Gemini to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n- **Firestore collection path:** This is the path to the Firestore collection that contains the documents that you want to perform the generative task on.\n- **Response field:** This is the name of the field in the Firestore document where you want the extension to store the response from the Model API.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query Gemini to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a genai model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI,\nthere is a list of models [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of generative models. For Google AI you will require an API key, whereas Vertex AI will authenticate using application default credentials. For more information see the [docs](https://firebase.google.com/docs/admin/setup#initialize-sdk).\n\n* Generative model: Which genai model do you want to use? For Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for example models/gemini-pro should be chosen as gemini-pro). For Vertex AI, there is a list of models [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n* Google AI API Key: If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used.\n\n* Collection Path: Path to the Firestore collection where text will be generated.\n\n* Prompt: Prompt. Use {{ handlebars }} for variable substitution from the created or updated doc. For example if you set this parameter as \"What is the capital of {{ country }}?\"\n\n* Variable fields: A comma separated list of fields to substitute as variables in the prompt.\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n* Hate Speech Threshold: Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.\n\n* Dangerous Content Threshold: Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.\n\n* Harassment Content Threshold: Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.\n\n* Sexual Content Threshold: Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**APIs Used**:\n\n* aiplatform.googleapis.com (Reason: For access to the Vertex AI Gemini API if this provider is chosen.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to read from your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with Gemini","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"6b22dde54140e955c7551c91ea4f618344b00eb5de1459f3479325cb8edba615","createTime":"2024-02-09T16:52:06.420939Z","id":"0.0.4-rc.2","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/83f908fddda27a47f001fb004512175dfab65416","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.4-rc.2@512.png","iconType":"PNG_512"}],"listing":{"state":"UNLISTED"},"tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.5","ref":"googlecloud/firestore-multimodal-genai@0.0.5","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.5","description":"Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.","apis":[{"apiName":"aiplatform.googleapis.com","reason":"For access to the Vertex AI Gemini API if this provider is chosen."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to read from your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Gemini model","type":"STRING","description":"Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)","required":true,"default":"gemini-pro"},{"param":"API_KEY","label":"Google AI API Key","type":"SECRET","description":"If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used."},{"param":"COLLECTION_NAME","label":"Firestore Collection Path","type":"STRING","description":"Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"","required":true},{"param":"VARIABLE_FIELDS","label":"Variable fields","type":"STRING","description":"A comma separated list of fields to substitute as variables in the prompt.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"},{"param":"HARM_CATEGORY_HATE_SPEECH","label":"Hate Speech Threshold","type":"SELECT","description":"Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_DANGEROUS_CONTENT","label":"Dangerous Content Threshold","type":"SELECT","description":"Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_HARASSMENT","label":"Harassment Content Threshold","type":"SELECT","description":"Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_SEXUALLY_EXPLICIT","label":"Sexual Content Threshold","type":"SELECT","description":"Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}],"preinstallContent":"This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n**Gemini API Provider**: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n**Gemini Model**: Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see:\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n**Firestore Collection Path**: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n**Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: **${param:COLLECTION_NAME}**.\n3. Add a document to this collection. You may have specified some variables (${param:VARIABLE_FIELDS}) during installation, to be substituted into your prompt. Add those fields to the Firestore document, and the extension will substitute the values into the prompt before calling Google AI.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message.\n   When processing is finished, the **${param:RESPONSE_FIELD}** field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Google AI documentation](https://ai.google.dev/docs).\n\n- Vertex AI: For more details on the Vertex AI Gemini API, see the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).\n\n## About the models\n\nThe extension gives you a choice of 2 models:\n\n- Gemini Pro\n- Gemini Pro Vision\n\n#### Multimodal Prompts\n\nThe Gemini Pro Vision model accepts multimodal prompts. This extension allows for multimodal prompting using this model.\n\nOn installation you may pick an `image` field. The image field must be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nNote that Google AI requires prompts to have both an image and text part, whereas Vertex AI allows gemini-pro-vision to be prompted with text only as well. If you have selected to use the Gemini Pro Vision model and have Google AI as a provider then any document handled by the extension must contain an image field.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will attempt to compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with the Gemini API\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.\n\n\n\n**Details**: This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n**Gemini API Provider**: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n**Gemini Model**: Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see:\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n**Firestore Collection Path**: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n**Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n\n* Gemini model: Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)\n\n* Google AI API Key: If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used.\n\n* Firestore Collection Path: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n\n* Prompt: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"\n\n* Variable fields: A comma separated list of fields to substitute as variables in the prompt.\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n* Hate Speech Threshold: Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.\n\n* Dangerous Content Threshold: Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.\n\n* Harassment Content Threshold: Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.\n\n* Sexual Content Threshold: Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**APIs Used**:\n\n* aiplatform.googleapis.com (Reason: For access to the Vertex AI Gemini API if this provider is chosen.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to read from your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with the Gemini API","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"247b38c4d6f6c02153a73891787c06bf75497e3be00b0d8e672ca8b93539a17f","createTime":"2024-02-15T14:29:49.034332Z","id":"0.0.5","releaseNotes":"- Update documentation\n  \n- Update extensions display name\n","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/f3eb2171da635a0d5a2b2eb30fc43130823423c7","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.5@512.png","iconType":"PNG_512"}],"listing":{"state":"REJECTED"},"tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.5-rc.0","ref":"googlecloud/firestore-multimodal-genai@0.0.5-rc.0","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.5-rc.0","description":"Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.","apis":[{"apiName":"aiplatform.googleapis.com","reason":"For access to the Vertex AI Gemini API if this provider is chosen."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to read from your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Gemini model","type":"STRING","description":"Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)","required":true,"default":"gemini-pro"},{"param":"API_KEY","label":"Google AI API Key","type":"SECRET","description":"If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used."},{"param":"COLLECTION_NAME","label":"Firestore Collection Path","type":"STRING","description":"Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"","required":true},{"param":"VARIABLE_FIELDS","label":"Variable fields","type":"STRING","description":"A comma separated list of fields to substitute as variables in the prompt.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"},{"param":"HARM_CATEGORY_HATE_SPEECH","label":"Hate Speech Threshold","type":"SELECT","description":"Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_DANGEROUS_CONTENT","label":"Dangerous Content Threshold","type":"SELECT","description":"Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_HARASSMENT","label":"Harassment Content Threshold","type":"SELECT","description":"Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_SEXUALLY_EXPLICIT","label":"Sexual Content Threshold","type":"SELECT","description":"Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}],"preinstallContent":"This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n**Gemini API Provider**: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n**Gemini Model**: Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see:\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n**Firestore Collection Path**: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n**Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: **${param:COLLECTION_NAME}**.\n3. Add a document to this collection. You may have specified some variables (${param:VARIABLE_FIELDS}) during installation, to be substituted into your prompt. Add those fields to the Firestore document, and the extension will substitute the values into the prompt before calling Google AI.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message.\n   When processing is finished, the **${param:RESPONSE_FIELD}** field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Google AI documentation](https://ai.google.dev/docs).\n\n- Vertex AI: For more details on the Vertex AI Gemini API, see the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).\n\n## About the models\n\nThe extension gives you a choice of 2 models:\n\n- Gemini Pro\n- Gemini Pro Vision\n\n#### Multimodal Prompts\n\nThe Gemini Pro Vision model accepts multimodal prompts. This extension allows for multimodal prompting using this model.\n\nOn installation you may pick an `image` field. The image field must be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nNote that Google AI requires prompts to have both an image and text part, whereas Vertex AI allows gemini-pro-vision to be prompted with text only as well. If you have selected to use the Gemini Pro Vision model and have Google AI as a provider then any document handled by the extension must contain an image field.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will attempt to compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with the Gemini API\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.\n\n\n\n**Details**: This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n**Gemini API Provider**: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n**Gemini Model**: Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see:\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n**Firestore Collection Path**: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n**Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n\n* Gemini model: Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)\n\n* Google AI API Key: If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used.\n\n* Firestore Collection Path: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n\n* Prompt: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"\n\n* Variable fields: A comma separated list of fields to substitute as variables in the prompt.\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n* Hate Speech Threshold: Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.\n\n* Dangerous Content Threshold: Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.\n\n* Harassment Content Threshold: Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.\n\n* Sexual Content Threshold: Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**APIs Used**:\n\n* aiplatform.googleapis.com (Reason: For access to the Vertex AI Gemini API if this provider is chosen.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to read from your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with the Gemini API","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"1159e248d78458ca4f1fce6e65d08227153f1bc9eee075f06f98ed9e6d1cc67b","createTime":"2024-02-15T13:56:27.967640Z","id":"0.0.5-rc.0","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/3d2b08953bcd3a156983b0e530e1845a36fc1956","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.5-rc.0@512.png","iconType":"PNG_512"}],"listing":{"state":"UNLISTED"},"tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.5-rc.1","ref":"googlecloud/firestore-multimodal-genai@0.0.5-rc.1","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.5-rc.1","description":"Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.","apis":[{"apiName":"aiplatform.googleapis.com","reason":"For access to the Vertex AI Gemini API if this provider is chosen."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to read from your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Gemini model","type":"STRING","description":"Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)","required":true,"default":"gemini-pro"},{"param":"API_KEY","label":"Google AI API Key","type":"SECRET","description":"If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used."},{"param":"COLLECTION_NAME","label":"Firestore Collection Path","type":"STRING","description":"Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"","required":true},{"param":"VARIABLE_FIELDS","label":"Variable fields","type":"STRING","description":"A comma separated list of fields to substitute as variables in the prompt.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"},{"param":"HARM_CATEGORY_HATE_SPEECH","label":"Hate Speech Threshold","type":"SELECT","description":"Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_DANGEROUS_CONTENT","label":"Dangerous Content Threshold","type":"SELECT","description":"Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_HARASSMENT","label":"Harassment Content Threshold","type":"SELECT","description":"Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_SEXUALLY_EXPLICIT","label":"Sexual Content Threshold","type":"SELECT","description":"Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}],"preinstallContent":"This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n**Gemini API Provider**: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n**Gemini Model**: Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see:\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n**Firestore Collection Path**: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n**Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: **${param:COLLECTION_NAME}**.\n3. Add a document to this collection. You may have specified some variables (${param:VARIABLE_FIELDS}) during installation, to be substituted into your prompt. Add those fields to the Firestore document, and the extension will substitute the values into the prompt before calling Google AI.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message.\n   When processing is finished, the **${param:RESPONSE_FIELD}** field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Google AI documentation](https://ai.google.dev/docs).\n\n- Vertex AI: For more details on the Vertex AI Gemini API, see the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).\n\n## About the models\n\nThe extension gives you a choice of 2 models:\n\n- Gemini Pro\n- Gemini Pro Vision\n\n#### Multimodal Prompts\n\nThe Gemini Pro Vision model accepts multimodal prompts. This extension allows for multimodal prompting using this model.\n\nOn installation you may pick an `image` field. The image field must be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nNote that Google AI requires prompts to have both an image and text part, whereas Vertex AI allows gemini-pro-vision to be prompted with text only as well. If you have selected to use the Gemini Pro Vision model and have Google AI as a provider then any document handled by the extension must contain an image field.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will attempt to compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with the Gemini API\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.\n\n\n\n**Details**: This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n**Gemini API Provider**: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n**Gemini Model**: Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see:\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n**Firestore Collection Path**: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n**Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n\n* Gemini model: Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)\n\n* Google AI API Key: If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used.\n\n* Firestore Collection Path: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n\n* Prompt: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"\n\n* Variable fields: A comma separated list of fields to substitute as variables in the prompt.\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n* Hate Speech Threshold: Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.\n\n* Dangerous Content Threshold: Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.\n\n* Harassment Content Threshold: Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.\n\n* Sexual Content Threshold: Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**APIs Used**:\n\n* aiplatform.googleapis.com (Reason: For access to the Vertex AI Gemini API if this provider is chosen.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to read from your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with the Gemini API","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"eb0e62233b8d99a6b7d30a7e6af66ad1975639f4f5cd655f99c660b0796b510f","createTime":"2024-02-15T14:16:32.251501Z","id":"0.0.5-rc.1","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/ce07d2587fa8166e8c8756e8a8a04e5fb1504a8d","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.5-rc.1@512.png","iconType":"PNG_512"}],"listing":{"state":"UNLISTED"},"tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.6","ref":"googlecloud/firestore-multimodal-genai@0.0.6","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.6","description":"Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.","apis":[{"apiName":"aiplatform.googleapis.com","reason":"For access to the Vertex AI Gemini API if this provider is chosen."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to read from your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Gemini model","type":"STRING","description":"Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)","required":true,"default":"gemini-pro"},{"param":"API_KEY","label":"Google AI API Key","type":"SECRET","description":"If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used."},{"param":"COLLECTION_NAME","label":"Firestore Collection Path","type":"STRING","description":"Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"","required":true},{"param":"VARIABLE_FIELDS","label":"Variable fields","type":"STRING","description":"A comma separated list of fields to substitute as variables in the prompt.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"},{"param":"HARM_CATEGORY_HATE_SPEECH","label":"Hate Speech Threshold","type":"SELECT","description":"Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_DANGEROUS_CONTENT","label":"Dangerous Content Threshold","type":"SELECT","description":"Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_HARASSMENT","label":"Harassment Content Threshold","type":"SELECT","description":"Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_SEXUALLY_EXPLICIT","label":"Sexual Content Threshold","type":"SELECT","description":"Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}],"preinstallContent":"This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n**Gemini API Provider**: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n**Gemini Model**: Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see:\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n**Firestore Collection Path**: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n**Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: **${param:COLLECTION_NAME}**.\n3. Add a document to this collection. You may have specified some variables (${param:VARIABLE_FIELDS}) during installation, to be substituted into your prompt. Add those fields to the Firestore document, and the extension will substitute the values into the prompt before calling Google AI.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message.\n   When processing is finished, the **${param:RESPONSE_FIELD}** field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Google AI documentation](https://ai.google.dev/docs).\n\n- Vertex AI: For more details on the Vertex AI Gemini API, see the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).\n\n## About the models\n\nThe extension gives you a choice of 2 models:\n\n- Gemini Pro\n- Gemini Pro Vision\n\n#### Multimodal Prompts\n\nThe Gemini Pro Vision model accepts multimodal prompts. This extension allows for multimodal prompting using this model.\n\nOn installation you may pick an `image` field. The image field must be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nNote that Google AI requires prompts to have both an image and text part, whereas Vertex AI allows gemini-pro-vision to be prompted with text only as well. If you have selected to use the Gemini Pro Vision model and have Google AI as a provider then any document handled by the extension must contain an image field.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will attempt to compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with the Gemini API\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.\n\n\n\n**Details**: This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n**Gemini API Provider**: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n**Gemini Model**: Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see:\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n**Firestore Collection Path**: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n**Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n\n* Gemini model: Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)\n\n* Google AI API Key: If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used.\n\n* Firestore Collection Path: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n\n* Prompt: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"\n\n* Variable fields: A comma separated list of fields to substitute as variables in the prompt.\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n* Hate Speech Threshold: Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.\n\n* Dangerous Content Threshold: Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.\n\n* Harassment Content Threshold: Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.\n\n* Sexual Content Threshold: Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**APIs Used**:\n\n* aiplatform.googleapis.com (Reason: For access to the Vertex AI Gemini API if this provider is chosen.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to read from your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with the Gemini API","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"477c78e6a417c17a5349492bf3901c76ffcbea97bca5aaf193a06c29fe5bc441","createTime":"2024-02-15T15:10:48.633604Z","id":"0.0.6","releaseNotes":"- Fixing a build issue\n","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/7b29205685d66b1577e662896935f5fbca07e95c","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.6@512.png","iconType":"PNG_512"}],"listing":{"state":"APPROVED"},"metrics":{},"tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.7","ref":"googlecloud/firestore-multimodal-genai@0.0.7","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.7","description":"Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.","apis":[{"apiName":"aiplatform.googleapis.com","reason":"For access to the Vertex AI Gemini API if this provider is chosen."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to read from your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Gemini model","type":"STRING","description":"Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)","required":true,"default":"gemini-pro"},{"param":"API_KEY","label":"Google AI API Key","type":"SECRET","description":"If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used."},{"param":"COLLECTION_NAME","label":"Firestore Collection Path","type":"STRING","description":"Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"","required":true},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"},{"param":"HARM_CATEGORY_HATE_SPEECH","label":"Hate Speech Threshold","type":"SELECT","description":"Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_DANGEROUS_CONTENT","label":"Dangerous Content Threshold","type":"SELECT","description":"Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_HARASSMENT","label":"Harassment Content Threshold","type":"SELECT","description":"Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_SEXUALLY_EXPLICIT","label":"Sexual Content Threshold","type":"SELECT","description":"Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}],"preinstallContent":"This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n**Gemini API Provider**: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: **${param:COLLECTION_NAME}**.\n3. Add a document to this collection. The extension will expect the handlebar variables in your prompt to have values specified as fields in your document. The extension will substitute the values into the prompt before passing the prompt to the generative model.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message. When processing is finished, the **${param:RESPONSE_FIELD}** field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Google AI documentation](https://ai.google.dev/docs).\n\n- Vertex AI: For more details on the Vertex AI Gemini API, see the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).\n\n## About the models\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThe Gemini Pro Vision model accepts multimodal prompts. This extension allows for multimodal prompting using this model.\n\nOn installation you may pick an `image` field. The image field must be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nNote that Google AI requires prompts to have both an image and text part, whereas Vertex AI allows gemini-pro-vision to be prompted with text only as well. If you have selected to use the Gemini Pro Vision model and have Google AI as a provider then any document handled by the extension must contain an image field.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with the Gemini API\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.\n\n\n\n**Details**: This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n**Gemini API Provider**: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n\n* Gemini model: Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)\n\n* Google AI API Key: If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used.\n\n* Firestore Collection Path: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n\n* Prompt: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n* Hate Speech Threshold: Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.\n\n* Dangerous Content Threshold: Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.\n\n* Harassment Content Threshold: Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.\n\n* Sexual Content Threshold: Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**APIs Used**:\n\n* aiplatform.googleapis.com (Reason: For access to the Vertex AI Gemini API if this provider is chosen.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to read from your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with the Gemini API","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"6d8e4b537d4fa2f3435c29e6c8a7ef4a51b93ad99334e24f8a1276088356acb9","createTime":"2024-02-16T15:58:28.378075Z","id":"0.0.7","releaseNotes":"- Update documentation\n\n- remove VARIABLE_FIELDS as a parameter\n","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/d891a2e6e8b69e3fe734a3722ebc1fc454ccbea1","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.7@512.png","iconType":"PNG_512"}],"listing":{"state":"APPROVED"},"metrics":{"activeInstallCount":"20"},"tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.7-rc.0","ref":"googlecloud/firestore-multimodal-genai@0.0.7-rc.0","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.7-rc.0","description":"Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.","apis":[{"apiName":"aiplatform.googleapis.com","reason":"For access to the Vertex AI Gemini API if this provider is chosen."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to read from your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Gemini model","type":"STRING","description":"Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)","required":true,"default":"gemini-pro"},{"param":"API_KEY","label":"Google AI API Key","type":"SECRET","description":"If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used."},{"param":"COLLECTION_NAME","label":"Firestore Collection Path","type":"STRING","description":"Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"","required":true},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"},{"param":"HARM_CATEGORY_HATE_SPEECH","label":"Hate Speech Threshold","type":"SELECT","description":"Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_DANGEROUS_CONTENT","label":"Dangerous Content Threshold","type":"SELECT","description":"Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_HARASSMENT","label":"Harassment Content Threshold","type":"SELECT","description":"Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_SEXUALLY_EXPLICIT","label":"Sexual Content Threshold","type":"SELECT","description":"Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}],"preinstallContent":"This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n**Gemini API Provider**: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: **${param:COLLECTION_NAME}**.\n3. Add a document to this collection. The extension will expect the handlebar variables in your prompt to have values specified as fields in your document. The extension will substitute the values into the prompt before passing the prompt to the generative model.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message. When processing is finished, the **${param:RESPONSE_FIELD}** field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Google AI documentation](https://ai.google.dev/docs).\n\n- Vertex AI: For more details on the Vertex AI Gemini API, see the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).\n\n## About the models\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThe Gemini Pro Vision model accepts multimodal prompts. This extension allows for multimodal prompting using this model.\n\nOn installation you may pick an `image` field. The image field must be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nNote that Google AI requires prompts to have both an image and text part, whereas Vertex AI allows gemini-pro-vision to be prompted with text only as well. If you have selected to use the Gemini Pro Vision model and have Google AI as a provider then any document handled by the extension must contain an image field.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with the Gemini API\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.\n\n\n\n**Details**: This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n**Gemini API Provider**: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n\n* Gemini model: Input the name of theWhich Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)\n\n* Google AI API Key: If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used.\n\n* Firestore Collection Path: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n\n* Prompt: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n* Hate Speech Threshold: Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.\n\n* Dangerous Content Threshold: Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.\n\n* Harassment Content Threshold: Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.\n\n* Sexual Content Threshold: Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**APIs Used**:\n\n* aiplatform.googleapis.com (Reason: For access to the Vertex AI Gemini API if this provider is chosen.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to read from your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with the Gemini API","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"9b2a2d6039c565ceee3eb828a85458579266f145fe4ce23831f3d4b9febcef70","createTime":"2024-02-16T15:35:07.463498Z","id":"0.0.7-rc.0","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/cf6ead0d2b40f03541dc94ecab0387adeb5da201","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.7-rc.0@512.png","iconType":"PNG_512"}],"listing":{"state":"UNLISTED"},"tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.8","ref":"googlecloud/firestore-multimodal-genai@0.0.8","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.8","description":"Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.","apis":[{"apiName":"aiplatform.googleapis.com","reason":"For access to the Vertex AI Gemini API if this provider is chosen."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to read from your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to generate conversations.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Gemini model","type":"STRING","description":"Input the name of the Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)","required":true,"default":"gemini-pro"},{"param":"API_KEY","label":"Google AI API Key","type":"SECRET","description":"If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used."},{"param":"COLLECTION_NAME","label":"Firestore Collection Path","type":"STRING","description":"Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"","required":true},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"},{"param":"HARM_CATEGORY_HATE_SPEECH","label":"Hate Speech Threshold","type":"SELECT","description":"Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_DANGEROUS_CONTENT","label":"Dangerous Content Threshold","type":"SELECT","description":"Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_HARASSMENT","label":"Harassment Content Threshold","type":"SELECT","description":"Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_SEXUALLY_EXPLICIT","label":"Sexual Content Threshold","type":"SELECT","description":"Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}],"preinstallContent":"This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n**Gemini API Provider**: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: **${param:COLLECTION_NAME}**.\n3. Add a document to this collection. The extension will expect the handlebar variables in your prompt to have values specified as fields in your document. The extension will substitute the values into the prompt before passing the prompt to the generative model.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message. When processing is finished, the **${param:RESPONSE_FIELD}** field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... }) // Include values for ${param:VARIABLE_FIELDS} fields\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Google AI documentation](https://ai.google.dev/docs).\n\n- Vertex AI: For more details on the Vertex AI Gemini API, see the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).\n\n## About the models\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThe Gemini Pro Vision model accepts multimodal prompts. This extension allows for multimodal prompting using this model.\n\nOn installation you may pick an `image` field. The image field must be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nNote that Google AI requires prompts to have both an image and text part, whereas Vertex AI allows gemini-pro-vision to be prompted with text only as well. If you have selected to use the Gemini Pro Vision model and have Google AI as a provider then any document handled by the extension must contain an image field.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with the Gemini API\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.\n\n\n\n**Details**: This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n**Gemini API Provider**: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n\n* Gemini model: Input the name of the Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)\n\n* Google AI API Key: If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used.\n\n* Firestore Collection Path: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n\n* Prompt: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n* Hate Speech Threshold: Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.\n\n* Dangerous Content Threshold: Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.\n\n* Harassment Content Threshold: Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.\n\n* Sexual Content Threshold: Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.\n\n\n\n**Cloud Functions:**\n\n* **generateText:** Listens to Firestore data writes to generate conversations.\n\n\n\n**APIs Used**:\n\n* aiplatform.googleapis.com (Reason: For access to the Vertex AI Gemini API if this provider is chosen.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to read from your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with the Gemini API","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"3112a7f0f94e85c193b4497f2bb4f9f9ca3a671679fa48fbf969601fd6cfb702","createTime":"2024-02-20T17:26:38.158650Z","id":"0.0.8","releaseNotes":"- fix typo in documentation\n","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/f6c5ee3283ced7368704d0e538df23d2629dd02b","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.8@512.png","iconType":"PNG_512"}],"listing":{"state":"APPROVED"},"metrics":{"activeInstallCount":"100"},"tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.9","ref":"googlecloud/firestore-multimodal-genai@0.0.9","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.9","description":"Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.","apis":[{"apiName":"aiplatform.googleapis.com","reason":"For access to the Vertex AI Gemini API if this provider is chosen."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to read from your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateOnCall","type":"firebaseextensions.v1beta.function","propertiesYaml":"httpsTrigger: {}\nlocation: ${LOCATION}\nruntime: nodejs18\n","description":"A callable function to perform generative AI tasks.","deletionPolicy":"DELETE"},{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to perform generative AI tasks.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Gemini model","type":"STRING","description":"Input the name of the Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)","required":true,"default":"gemini-pro"},{"param":"API_KEY","label":"Google AI API Key","type":"SECRET","description":"If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used."},{"param":"COLLECTION_NAME","label":"Firestore Collection Path","type":"STRING","description":"Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"","required":true},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations). Note that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai). A list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"},{"param":"HARM_CATEGORY_HATE_SPEECH","label":"Hate Speech Threshold","type":"SELECT","description":"Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_DANGEROUS_CONTENT","label":"Dangerous Content Threshold","type":"SELECT","description":"Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_HARASSMENT","label":"Harassment Content Threshold","type":"SELECT","description":"Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_SEXUALLY_EXPLICIT","label":"Sexual Content Threshold","type":"SELECT","description":"Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}],"preinstallContent":"This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Gemini API Provider** This extension makes use of the Gemini family of models. Currently the extension supports the Google AI Gemini API and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs [here](https://cloud.google.com/vertex-ai/docs/generative-ai/migrate/migrate-google-ai).\n\nNote that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai).\n\nA list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).\n\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nAdditionally the extension deploys a callable function, which may be called with data containing the values for handlebar substitution.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: **${param:COLLECTION_NAME}**.\n3. Add a document to this collection. The extension will expect the handlebar variables in your prompt to have values specified as fields in your document. The extension will substitute the values into the prompt before passing the prompt to the generative model.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message. When processing is finished, the **${param:RESPONSE_FIELD}** field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... })\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Google AI documentation](https://ai.google.dev/docs).\n\n- Vertex AI: For more details on the Vertex AI Gemini API, see the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).\n\n## About the models\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThe Gemini Pro Vision model accepts multimodal prompts. This extension allows for multimodal prompting using this model.\n\nOn installation you may pick an `image` field. The image field must be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nNote that Google AI requires prompts to have both an image and text part, whereas Vertex AI allows gemini-pro-vision to be prompted with text only as well. If you have selected to use the Gemini Pro Vision model and have Google AI as a provider then any document handled by the extension must contain an image field.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with the Gemini API\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.\n\n\n\n**Details**: This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Gemini API Provider** This extension makes use of the Gemini family of models. Currently the extension supports the Google AI Gemini API and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs [here](https://cloud.google.com/vertex-ai/docs/generative-ai/migrate/migrate-google-ai).\n\nNote that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai).\n\nA list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).\n\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nAdditionally the extension deploys a callable function, which may be called with data containing the values for handlebar substitution.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n\n* Gemini model: Input the name of the Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)\n\n* Google AI API Key: If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used.\n\n* Firestore Collection Path: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n\n* Prompt: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations). Note that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai). A list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n* Hate Speech Threshold: Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.\n\n* Dangerous Content Threshold: Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.\n\n* Harassment Content Threshold: Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.\n\n* Sexual Content Threshold: Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.\n\n\n\n**Cloud Functions:**\n\n* **generateOnCall:** A callable function to perform generative AI tasks.\n\n* **generateText:** Listens to Firestore data writes to perform generative AI tasks.\n\n\n\n**APIs Used**:\n\n* aiplatform.googleapis.com (Reason: For access to the Vertex AI Gemini API if this provider is chosen.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to read from your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with the Gemini API","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/memory","label":"Function memory","type":"SELECT","description":"How much memory should be allocated to each v1 function?","options":[{"value":"128","label":"128MB"},{"value":"256","label":"256MB"},{"value":"512","label":"512MB"},{"value":"1024","label":"1GB"},{"value":"2048","label":"2GB"},{"value":"4096","label":"4GB"},{"value":"8192","label":"8GB"}],"default":"256","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"9e5849a5be44913311a38e3c7309ee6836076ca2c4d16b8be4152955d4dc90d3","createTime":"2024-04-08T13:02:09.530023Z","id":"0.0.9","releaseNotes":"- feature: Add callable function\n\n- Add docs on regional support for Gemini APIs\n","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/cceaf70bf05168daf7f00268386eee5fb60e6198","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.9@512.png","iconType":"PNG_512"}],"listing":{"state":"APPROVED"},"metrics":{"activeInstallCount":"60"},"tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/0.0.9-rc.0","ref":"googlecloud/firestore-multimodal-genai@0.0.9-rc.0","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"0.0.9-rc.0","description":"Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.","apis":[{"apiName":"aiplatform.googleapis.com","reason":"For access to the Vertex AI Gemini API if this provider is chosen."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to read from your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateOnCall","type":"firebaseextensions.v1beta.function","propertiesYaml":"httpsTrigger: {}\nlocation: ${LOCATION}\nruntime: nodejs18\n","description":"A callable function to perform generative AI tasks.","deletionPolicy":"DELETE"},{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to perform generative AI tasks.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Gemini model","type":"STRING","description":"Input the name of the Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)","required":true,"default":"gemini-pro"},{"param":"API_KEY","label":"Google AI API Key","type":"SECRET","description":"If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used."},{"param":"COLLECTION_NAME","label":"Firestore Collection Path","type":"STRING","description":"Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"","required":true},{"param":"IMAGE_FIELD","label":"Image field (Gemini Pro Vision)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations). Note that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai). A list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"},{"param":"HARM_CATEGORY_HATE_SPEECH","label":"Hate Speech Threshold","type":"SELECT","description":"Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_DANGEROUS_CONTENT","label":"Dangerous Content Threshold","type":"SELECT","description":"Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_HARASSMENT","label":"Harassment Content Threshold","type":"SELECT","description":"Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_SEXUALLY_EXPLICIT","label":"Sexual Content Threshold","type":"SELECT","description":"Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}],"preinstallContent":"This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Gemini API Provider** This extension makes use of the Gemini family of models. Currently the extension supports the Google AI Gemini API and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs [here](https://cloud.google.com/vertex-ai/docs/generative-ai/migrate/migrate-google-ai).\n\nNote that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai).\n\nA list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).\n\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nAdditionally the extension deploys a callable function, which may be called with data containing the values for handlebar substitution.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: **${param:COLLECTION_NAME}**.\n3. Add a document to this collection. The extension will expect the handlebar variables in your prompt to have values specified as fields in your document. The extension will substitute the values into the prompt before passing the prompt to the generative model.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message. When processing is finished, the **${param:RESPONSE_FIELD}** field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... })\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Google AI documentation](https://ai.google.dev/docs).\n\n- Vertex AI: For more details on the Vertex AI Gemini API, see the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).\n\n## About the models\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThe Gemini Pro Vision model accepts multimodal prompts. This extension allows for multimodal prompting using this model.\n\nOn installation you may pick an `image` field. The image field must be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nNote that Google AI requires prompts to have both an image and text part, whereas Vertex AI allows gemini-pro-vision to be prompted with text only as well. If you have selected to use the Gemini Pro Vision model and have Google AI as a provider then any document handled by the extension must contain an image field.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with the Gemini API\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.\n\n\n\n**Details**: This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Gemini API Provider** This extension makes use of the Gemini family of models. Currently the extension supports the Google AI Gemini API and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs [here](https://cloud.google.com/vertex-ai/docs/generative-ai/migrate/migrate-google-ai).\n\nNote that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai).\n\nA list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).\n\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nAdditionally the extension deploys a callable function, which may be called with data containing the values for handlebar substitution.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n\n* Gemini model: Input the name of the Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)\n\n* Google AI API Key: If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used.\n\n* Firestore Collection Path: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n\n* Prompt: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"\n\n* Image field (Gemini Pro Vision): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision model.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations). Note that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai). A list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n* Hate Speech Threshold: Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.\n\n* Dangerous Content Threshold: Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.\n\n* Harassment Content Threshold: Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.\n\n* Sexual Content Threshold: Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.\n\n\n\n**Cloud Functions:**\n\n* **generateOnCall:** A callable function to perform generative AI tasks.\n\n* **generateText:** Listens to Firestore data writes to perform generative AI tasks.\n\n\n\n**APIs Used**:\n\n* aiplatform.googleapis.com (Reason: For access to the Vertex AI Gemini API if this provider is chosen.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to read from your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with the Gemini API","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/memory","label":"Function memory","type":"SELECT","description":"How much memory should be allocated to each v1 function?","options":[{"value":"128","label":"128MB"},{"value":"256","label":"256MB"},{"value":"512","label":"512MB"},{"value":"1024","label":"1GB"},{"value":"2048","label":"2GB"},{"value":"4096","label":"4GB"},{"value":"8192","label":"8GB"}],"default":"256","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"7ec8eb8559e2270ba869963ba12601a7c38796fd03afed68e96e9d6405f72682","createTime":"2024-04-08T10:40:13.733015Z","id":"0.0.9-rc.0","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/6ba1398e54667b58e831ff87dd7d6512067cfaba","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_0.0.9-rc.0@512.png","iconType":"PNG_512"}],"listing":{"state":"UNLISTED"},"tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/1.0.0","ref":"googlecloud/firestore-multimodal-genai@1.0.0","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"1.0.0","description":"Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.","apis":[{"apiName":"aiplatform.googleapis.com","reason":"For access to the Vertex AI Gemini API if this provider is chosen."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to read from your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateOnCall","type":"firebaseextensions.v1beta.function","propertiesYaml":"httpsTrigger: {}\nlocation: ${LOCATION}\nruntime: nodejs18\n","description":"A callable function to perform generative AI tasks.","deletionPolicy":"DELETE"},{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to perform generative AI tasks.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Gemini model","type":"STRING","description":"Input the name of the Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)","required":true,"default":"gemini-pro"},{"param":"API_KEY","label":"Google AI API Key","type":"SECRET","description":"If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used."},{"param":"COLLECTION_NAME","label":"Firestore Collection Path","type":"STRING","description":"Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"","required":true},{"param":"IMAGE_FIELD","label":"Image field (Gemini Vision Models ONLY)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision models. If you are using a text-only model, you should leave this field blank.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations). Note that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai). A list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"},{"param":"HARM_CATEGORY_HATE_SPEECH","label":"Hate Speech Threshold","type":"SELECT","description":"Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_DANGEROUS_CONTENT","label":"Dangerous Content Threshold","type":"SELECT","description":"Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_HARASSMENT","label":"Harassment Content Threshold","type":"SELECT","description":"Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_SEXUALLY_EXPLICIT","label":"Sexual Content Threshold","type":"SELECT","description":"Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}],"preinstallContent":"This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Gemini API Provider** This extension makes use of the Gemini family of models. Currently the extension supports the Google AI Gemini API and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs [here](https://cloud.google.com/vertex-ai/docs/generative-ai/migrate/migrate-google-ai).\n\nNote that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai).\n\nA list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).\n\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nAdditionally the extension deploys a callable function, which may be called with data containing the values for handlebar substitution.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: **${param:COLLECTION_NAME}**.\n3. Add a document to this collection. The extension will expect the handlebar variables in your prompt to have values specified as fields in your document. The extension will substitute the values into the prompt before passing the prompt to the generative model.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message. When processing is finished, the **${param:RESPONSE_FIELD}** field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... })\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Google AI documentation](https://ai.google.dev/docs).\n\n- Vertex AI: For more details on the Vertex AI Gemini API, see the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).\n\n## About the models\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThe Gemini Pro Vision model accepts multimodal prompts. This extension allows for multimodal prompting using this model.\n\nOn installation you may pick an `image` field. The image field must be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nNote that Google AI requires prompts to have both an image and text part, whereas Vertex AI allows gemini-pro-vision to be prompted with text only as well. If you have selected to use the Gemini Pro Vision model and have Google AI as a provider then any document handled by the extension must contain an image field.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with the Gemini API\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.\n\n\n\n**Details**: This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Gemini API Provider** This extension makes use of the Gemini family of models. Currently the extension supports the Google AI Gemini API and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs [here](https://cloud.google.com/vertex-ai/docs/generative-ai/migrate/migrate-google-ai).\n\nNote that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai).\n\nA list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).\n\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nAdditionally the extension deploys a callable function, which may be called with data containing the values for handlebar substitution.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n\n* Gemini model: Input the name of the Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)\n\n* Google AI API Key: If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used.\n\n* Firestore Collection Path: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n\n* Prompt: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"\n\n* Image field (Gemini Vision Models ONLY): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision models. If you are using a text-only model, you should leave this field blank.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations). Note that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai). A list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n* Hate Speech Threshold: Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.\n\n* Dangerous Content Threshold: Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.\n\n* Harassment Content Threshold: Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.\n\n* Sexual Content Threshold: Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.\n\n\n\n**Cloud Functions:**\n\n* **generateOnCall:** A callable function to perform generative AI tasks.\n\n* **generateText:** Listens to Firestore data writes to perform generative AI tasks.\n\n\n\n**APIs Used**:\n\n* aiplatform.googleapis.com (Reason: For access to the Vertex AI Gemini API if this provider is chosen.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to read from your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with the Gemini API","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/memory","label":"Function memory","type":"SELECT","description":"How much memory should be allocated to each v1 function?","options":[{"value":"128","label":"128MB"},{"value":"256","label":"256MB"},{"value":"512","label":"512MB"},{"value":"1024","label":"1GB"},{"value":"2048","label":"2GB"},{"value":"4096","label":"4GB"},{"value":"8192","label":"8GB"}],"default":"256","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"85e74b4cf3bc36c01f2d67f4266b051f187f9688e2b84c23c56e2f35a56d677f","createTime":"2024-04-25T15:31:32.490715Z","id":"1.0.0","releaseNotes":"- **Breaking**: made whether IMAGE_FIELDS parameter is defined determine whether the extension calls Gemini with an image.\n\n- Fixed: update dependencies to latest versions, fixes critical protobufjs dependency vulnerability\n\nchore - remove TODO security comment in code\n","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/797ecd86fda524ed7f494985080d5ac03b064e4c","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_1.0.0@512.png","iconType":"PNG_512"}],"listing":{"state":"APPROVED"},"metrics":{"activeInstallCount":"40"},"tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"},{"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/1.0.0-rc.0","ref":"googlecloud/firestore-multimodal-genai@1.0.0-rc.0","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"1.0.0-rc.0","description":"Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.","apis":[{"apiName":"aiplatform.googleapis.com","reason":"For access to the Vertex AI Gemini API if this provider is chosen."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to read from your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateOnCall","type":"firebaseextensions.v1beta.function","propertiesYaml":"httpsTrigger: {}\nlocation: ${LOCATION}\nruntime: nodejs18\n","description":"A callable function to perform generative AI tasks.","deletionPolicy":"DELETE"},{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to perform generative AI tasks.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Gemini model","type":"STRING","description":"Input the name of the Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)","required":true,"default":"gemini-pro"},{"param":"API_KEY","label":"Google AI API Key","type":"SECRET","description":"If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used."},{"param":"COLLECTION_NAME","label":"Firestore Collection Path","type":"STRING","description":"Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"","required":true},{"param":"IMAGE_FIELD","label":"Image field (Gemini Vision Models ONLY)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision models. If you are using a text-only model, you should leave this field blank.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations). Note that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai). A list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"},{"param":"HARM_CATEGORY_HATE_SPEECH","label":"Hate Speech Threshold","type":"SELECT","description":"Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_DANGEROUS_CONTENT","label":"Dangerous Content Threshold","type":"SELECT","description":"Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_HARASSMENT","label":"Harassment Content Threshold","type":"SELECT","description":"Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_SEXUALLY_EXPLICIT","label":"Sexual Content Threshold","type":"SELECT","description":"Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}],"preinstallContent":"This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Gemini API Provider** This extension makes use of the Gemini family of models. Currently the extension supports the Google AI Gemini API and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs [here](https://cloud.google.com/vertex-ai/docs/generative-ai/migrate/migrate-google-ai).\n\nNote that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai).\n\nA list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).\n\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nAdditionally the extension deploys a callable function, which may be called with data containing the values for handlebar substitution.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: **${param:COLLECTION_NAME}**.\n3. Add a document to this collection. The extension will expect the handlebar variables in your prompt to have values specified as fields in your document. The extension will substitute the values into the prompt before passing the prompt to the generative model.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message. When processing is finished, the **${param:RESPONSE_FIELD}** field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... })\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Google AI documentation](https://ai.google.dev/docs).\n\n- Vertex AI: For more details on the Vertex AI Gemini API, see the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).\n\n## About the models\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThe Gemini Pro Vision model accepts multimodal prompts. This extension allows for multimodal prompting using this model.\n\nOn installation you may pick an `image` field. The image field must be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nNote that Google AI requires prompts to have both an image and text part, whereas Vertex AI allows gemini-pro-vision to be prompted with text only as well. If you have selected to use the Gemini Pro Vision model and have Google AI as a provider then any document handled by the extension must contain an image field.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with the Gemini API\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.\n\n\n\n**Details**: This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Gemini API Provider** This extension makes use of the Gemini family of models. Currently the extension supports the Google AI Gemini API and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs [here](https://cloud.google.com/vertex-ai/docs/generative-ai/migrate/migrate-google-ai).\n\nNote that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai).\n\nA list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).\n\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nAdditionally the extension deploys a callable function, which may be called with data containing the values for handlebar substitution.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n\n* Gemini model: Input the name of the Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)\n\n* Google AI API Key: If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used.\n\n* Firestore Collection Path: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n\n* Prompt: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"\n\n* Image field (Gemini Vision Models ONLY): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision models. If you are using a text-only model, you should leave this field blank.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations). Note that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai). A list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n* Hate Speech Threshold: Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.\n\n* Dangerous Content Threshold: Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.\n\n* Harassment Content Threshold: Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.\n\n* Sexual Content Threshold: Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.\n\n\n\n**Cloud Functions:**\n\n* **generateOnCall:** A callable function to perform generative AI tasks.\n\n* **generateText:** Listens to Firestore data writes to perform generative AI tasks.\n\n\n\n**APIs Used**:\n\n* aiplatform.googleapis.com (Reason: For access to the Vertex AI Gemini API if this provider is chosen.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to read from your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with the Gemini API","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/memory","label":"Function memory","type":"SELECT","description":"How much memory should be allocated to each v1 function?","options":[{"value":"128","label":"128MB"},{"value":"256","label":"256MB"},{"value":"512","label":"512MB"},{"value":"1024","label":"1GB"},{"value":"2048","label":"2GB"},{"value":"4096","label":"4GB"},{"value":"8192","label":"8GB"}],"default":"256","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"1320d2ceb853099277852acf0570bd4fc2f5c54f9b715d499fabb5dc14140cb5","createTime":"2024-04-25T13:09:16.325891Z","id":"1.0.0-rc.0","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/3efe82382a77707abf554834e4449295157f37f4","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_1.0.0-rc.0@512.png","iconType":"PNG_512"}],"listing":{"state":"UNLISTED"},"tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"}]}
[debug] [2024-05-03T17:07:41.967Z] >>> [apiv2][query] GET https://firebaseextensions.googleapis.com/v1beta/publishers/googlecloud/extensions/firestore-multimodal-genai/versions/1.0.0 [none]
[debug] [2024-05-03T17:07:43.310Z] <<< [apiv2][status] GET https://firebaseextensions.googleapis.com/v1beta/publishers/googlecloud/extensions/firestore-multimodal-genai/versions/1.0.0 200
[debug] [2024-05-03T17:07:43.312Z] <<< [apiv2][body] GET https://firebaseextensions.googleapis.com/v1beta/publishers/googlecloud/extensions/firestore-multimodal-genai/versions/1.0.0 {"name":"publishers/googlecloud/extensions/firestore-multimodal-genai/versions/1.0.0","ref":"googlecloud/firestore-multimodal-genai@1.0.0","spec":{"specVersion":"v1beta","name":"firestore-multimodal-genai","version":"1.0.0","description":"Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.","apis":[{"apiName":"aiplatform.googleapis.com","reason":"For access to the Vertex AI Gemini API if this provider is chosen."}],"roles":[{"role":"datastore.user","reason":"Allows this extension to access Cloud Firestore to read and process added messages."},{"role":"storage.objectAdmin","reason":"Allows the extension to read from your Cloud Storage."},{"role":"aiplatform.user","reason":"Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen."}],"resources":[{"name":"generateOnCall","type":"firebaseextensions.v1beta.function","propertiesYaml":"httpsTrigger: {}\nlocation: ${LOCATION}\nruntime: nodejs18\n","description":"A callable function to perform generative AI tasks.","deletionPolicy":"DELETE"},{"name":"generateText","type":"firebaseextensions.v1beta.function","propertiesYaml":"availableMemoryMb: 2048\neventTrigger:\n  eventType: providers/cloud.firestore/eventTypes/document.write\n  resource: projects/${PROJECT_ID}/databases/(default)/documents/${COLLECTION_NAME}/{summaryId}\nlocation: ${LOCATION}\nruntime: nodejs18\ntimeout: 540s\n","description":"Listens to Firestore data writes to perform generative AI tasks.","deletionPolicy":"DELETE"}],"billingRequired":true,"author":{"authorName":"Google Cloud","url":"https://cloud.google.com"},"contributors":[{"authorName":"Invertase","email":"oss@invertase.io","url":"https://github.com/invertase"},{"authorName":"Jacob Cable","email":"jacob@invertase.io","url":"https://github.com/cabljac"},{"authorName":"Mais Alheraki","email":"mais@invertase.io","url":"https://github.com/pr-Mais"}],"license":"Apache-2.0","releaseNotesUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai/CHANGELOG.md","sourceUrl":"https://github.com/GoogleCloudPlatform/firebase-extensions/tree/main/firestore-multimodal-genai","params":[{"param":"GENERATIVE_AI_PROVIDER","label":"Gemini API Provider","type":"SELECT","description":"This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.","required":true,"options":[{"value":"google-ai","label":"Google AI"},{"value":"vertex-ai","label":"Vertex AI"}],"default":"google-ai"},{"param":"MODEL","label":"Gemini model","type":"STRING","description":"Input the name of the Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)","required":true,"default":"gemini-pro"},{"param":"API_KEY","label":"Google AI API Key","type":"SECRET","description":"If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used."},{"param":"COLLECTION_NAME","label":"Firestore Collection Path","type":"STRING","description":"Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.","required":true,"default":"generate","validationRegex":"^[^/]+(/[^/]+/[^/]+)*$","validationErrorMessage":"Must be a valid Cloud Firestore Collection"},{"param":"PROMPT","label":"Prompt","type":"STRING","description":"This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"","required":true},{"param":"IMAGE_FIELD","label":"Image field (Gemini Vision Models ONLY)","type":"STRING","description":"A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision models. If you are using a text-only model, you should leave this field blank.","validationRegex":"^[a-zA-Z0-9_]+(,[a-zA-Z0-9_]+)*$","validationErrorMessage":"Field names may only use upper and lowercase letters from A to Z, underscores, or numbers, and may only be separated by commas. Trailing commas and empty variable names are not allowed."},{"param":"RESPONSE_FIELD","label":"Response Field","type":"STRING","description":"The field in the message document into which to put the response.","required":true,"default":"output"},{"param":"LOCATION","label":"Cloud Functions location","type":"SELECT","description":"Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations). Note that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai). A list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).","required":true,"options":[{"value":"us-central1","label":"Iowa (us-central1)"},{"value":"us-east1","label":"South Carolina (us-east1)"},{"value":"us-east4","label":"Northern Virginia (us-east4)"},{"value":"us-west2","label":"Los Angeles (us-west2)"},{"value":"us-west3","label":"Salt Lake City (us-west3)"},{"value":"us-west4","label":"Las Vegas (us-west4)"},{"value":"europe-central2","label":"Warsaw (europe-central2)"},{"value":"europe-west1","label":"Belgium (europe-west1)"},{"value":"europe-west2","label":"London (europe-west2)"},{"value":"europe-west3","label":"Frankfurt (europe-west3)"},{"value":"europe-west6","label":"Zurich (europe-west6)"},{"value":"asia-east2","label":"Hong Kong (asia-east2)"},{"value":"asia-northeast1","label":"Tokyo (asia-northeast1)"},{"value":"asia-northeast2","label":"Osaka (asia-northeast2)"},{"value":"asia-northeast3","label":"Seoul (asia-northeast3)"},{"value":"asia-south1","label":"Mumbai (asia-south1)"},{"value":"asia-southeast2","label":"Jakarta (asia-southeast2)"},{"value":"northamerica-northeast1","label":"Montreal (northamerica-northeast1)"},{"value":"southamerica-east1","label":"Sao Paulo (southamerica-east1)"},{"value":"australia-southeast1","label":"Sydney (australia-southeast1)"}],"immutable":true},{"param":"TEMPERATURE","label":"Temperature","type":"STRING","description":"Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_P","label":"Nucleus sampling probability","type":"STRING","description":"If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.","validationRegex":"^(?:0*(?:\\.\\d+)?|1(\\.0*)?)$","validationErrorMessage":"Please specify a decimal representation of a number between 0 and 1."},{"param":"TOP_K","label":"Sampling strategy parameter","type":"STRING","description":"If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATE_COUNT","label":"Candidate count","type":"STRING","description":"When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.","default":"1","validationRegex":"^[1-9][0-9]*","validationErrorMessage":"Please specify a positive integer."},{"param":"CANDIDATES_FIELD","label":"Candidates field","type":"STRING","description":"The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.","default":"candidates"},{"param":"HARM_CATEGORY_HATE_SPEECH","label":"Hate Speech Threshold","type":"SELECT","description":"Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_DANGEROUS_CONTENT","label":"Dangerous Content Threshold","type":"SELECT","description":"Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_HARASSMENT","label":"Harassment Content Threshold","type":"SELECT","description":"Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"},{"param":"HARM_CATEGORY_SEXUALLY_EXPLICIT","label":"Sexual Content Threshold","type":"SELECT","description":"Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.","options":[{"value":"HARM_BLOCK_THRESHOLD_UNSPECIFIED","label":"Default"},{"value":"BLOCK_LOW_AND_ABOVE","label":"Block low and above"},{"value":"BLOCK_MEDIUM_AND_ABOVE","label":"Block medium and above"},{"value":"BLOCK_ONLY_HIGH","label":"Block only high"},{"value":"BLOCK_NONE","label":"Block none"}],"default":"HARM_BLOCK_THRESHOLD_UNSPECIFIED"}],"preinstallContent":"This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Gemini API Provider** This extension makes use of the Gemini family of models. Currently the extension supports the Google AI Gemini API and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs [here](https://cloud.google.com/vertex-ai/docs/generative-ai/migrate/migrate-google-ai).\n\nNote that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai).\n\nA list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).\n\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nAdditionally the extension deploys a callable function, which may be called with data containing the values for handlebar substitution.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n","postinstallContent":"## See It In Action\n\nYou can test out this extension right away!\n\n1. Go to your Cloud Firestore dashboard in the Firebase console.\n2. If it doesn't exist, create the collection that you specified during installation: **${param:COLLECTION_NAME}**.\n3. Add a document to this collection. The extension will expect the handlebar variables in your prompt to have values specified as fields in your document. The extension will substitute the values into the prompt before passing the prompt to the generative model.\n4. In a few seconds, you'll see a status field appear in the document. This field will update as the extension processes the message. When processing is finished, the **${param:RESPONSE_FIELD}** field of the document should be populated with the response generated by Google AI.\n\nNote: You can also use the Firebase Admin SDK to add a document:\n\n```javascript\nconst ref = await admin\n    .firestore()\n    .collection(\"${param:COLLECTION_NAME}\")\n    .add({ ... })\n\nref.onSnapshot(snap => {\n    if (snap.get('${param:RESPONSE_FIELD}')) console.log(\n        'RESPONSE:',\n        snap.get('${param:RESPONSE_FIELD}')\n    )\n})\n```\n\n## About the providers\n\nThe extension gives you a choice of what provider to use for the available models:\n\n- Google AI: For more details on this Gemini API, see the [Google AI documentation](https://ai.google.dev/docs).\n\n- Vertex AI: For more details on the Vertex AI Gemini API, see the [Vertex AI documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini).\n\n## About the models\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThe Gemini Pro Vision model accepts multimodal prompts. This extension allows for multimodal prompting using this model.\n\nOn installation you may pick an `image` field. The image field must be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nNote that Google AI requires prompts to have both an image and text part, whereas Vertex AI allows gemini-pro-vision to be prompted with text only as well. If you have selected to use the Gemini Pro Vision model and have Google AI as a provider then any document handled by the extension must contain an image field.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension compress and resize images that fall above this limit.\n\n## Handling errors\n\nIf the extension encounters an error, it will write an error message to the document in `status` field. You can use this field to monitor for errors in your documents. Currently some errors will instruct you to visit the Cloud Function logs for the extension, to avoid exposing sensitive information.\n\n## Monitoring\n\nAs a best practice, you can [monitor the activity](https://firebase.google.com/docs/extensions/manage-installed-extensions#monitor) of your installed extension, including checks on its health, usage, and logs.\n","readmeContent":"# Multimodal Tasks with the Gemini API\n\n**Author**: Google Cloud (**[https://cloud.google.com](https://cloud.google.com)**)\n\n**Description**: Performs multimodel generative tasks on text and images, customizable with prompt engineering, using Gemini models and Firestore.\n\n\n\n**Details**: This extension allows you to perform generative tasks using the Gemini API, a custom prompt, and Firestore.\n\nOn installation, you will be asked to provide the following information:\n\n- **Gemini API Provider** This extension makes use of the Gemini family of models. Currently the extension supports the Google AI Gemini API and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs [here](https://cloud.google.com/vertex-ai/docs/generative-ai/migrate/migrate-google-ai).\n\nNote that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai).\n\nA list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).\n\n**Gemini Model**: Input the name of which Gemini model you would like to use. To view available models for each provider, see:\n\n- [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models)\n- [Google AI Gemini models](https://ai.google.dev/models/gemini)\n  **Firestore Collection Path**: This extension will listen to the specified collection(s) for new task documents.\n  **Prompt**: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document.\n\nThis extension will listen to the specified collection for new documents. When such a document is added, the extension will:\n\n1. Substitute any variables from the document into the prompt.\n2. Query the Gemini API to generate a response based on the prompt.\n3. Write the response from the Model API back to the triggering document in the response field.\n\nAdditionally the extension deploys a callable function, which may be called with data containing the values for handlebar substitution.\n\nNote that the extension only supports top-level handlebars variables, substitution into nested handlebar templates is not supported.\n\nEach instance of the extension should be configured to perform one particular task. If you have multiple tasks, you can install multiple instances.\n\nFor example, you could use this extension to:\n\n- Predict star ratings on a collection of product reviews.\n- Classify customer feedback as positive, negative, or neutral.\n- Summarize long articles.\n- Extract named entities from text.\n- Generate creative text, such as poems or code.\n\nHere’s an example prompt used for predicting star ratings on a collection of product reviews:\n\n```\nProvide a star rating from 1-5 of the following review text: “This is a truly incredible water bottle, I keep it with me all the time when I’m traveling and it has never let me down.”\n5\n\nProvide a star rating from 1-5 of the following review text: “I really enjoyed the water bottle, I just wish they carried this in a larger size as I go for long hikes. But overall the aesthetic, manufacturing, and functional design are great for what I needed.”\n4\n\nProvide a star rating from 1-5 of the following review text: “The water bottle was fine, although the design was a bit lacking and could be improved.”\n3\n\nProvide a star rating from 1-5 of the following review text: “Please don’t get this water bottle, there are major design flaws, for example the cap doesn’t screw on fully so water leaks into my backpack all the time.”\n1\n\nProvide a star rating from 1-5 of the following review text: \\“{{review_text}}\\”\n```\n\nIn this case, `review_text`` is a field of the Firestore document and will be substituted into the prompt when querying.\n\n### Choosing a generative model\n\nWhen installing this extension you will be prompted to pick a Gemini model.\n\nFor Google AI the list of supported models is [here](https://ai.google.dev/models/gemini), and this parameter should be set to the model name, the second segment of the model code (for\nexample models/gemini-pro should be chosen as gemini-pro).\n\nFor Vertex AI, the list of models is [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models).\n\n#### Multimodal Prompts\n\nThis extension supports providing multimodal prompts. To use this feature, select the Gemini Pro Vision model on installation, and provide an Image Field parameter. The Image Field parameter should be the name of a document field in firestore.\n\nWhen you select these options, any document handled by the extension must contain an image field. The image field must be a string, and can either be the Cloud Storage URL of an object (e.g `gs://my-bucket.appspot.com/filename.png`). This image will then be provided as part of the prompt to Gemini Pro Vision.\n\nThe Gemini Pro Vision API has a limit on image sizes. For Google AI this limit is currently 1MB, and for Vertex AI this limit is 4MB. This extension will compress and resize images that fall above this limit.\n\n### Troubleshooting timeout/PROCESSING errors\n\nThis extension will update the state of a document that is being processed within that status field of that document. When using Gemini Pro Vision with large images, there is a possibility that the process of compressing and resizing the image will exceed the extension's cloud function memory. By default this extension deploys a cloud function with 2GiB of memory, which should handle most use cases. If for some reason this is too much memory, you may reconfigure the function in the GCP console.\n\n### Regenerating a response\n\nChanging the state field of a completed document's status from `COMPLETED` to anything else will retrigger the extension for that document.\n\n## Billing\n\nTo install an extension, your project must be on the Blaze (pay as you go) plan. You will be charged a small amount (typically around $0.01/month) for the Firebase resources required by this extension (even if it is not used).\nThis extension uses other Firebase and Google Cloud Platform services, which have associated charges if you exceed the service’s no-cost tier:\n\n- Cloud Firestore\n- Cloud Functions (See [FAQs](https://firebase.google.com/support/faq#extensions-pricing))\n- Associated costs for using Vertex AI ([see their pricing](https://cloud.google.com/vertex-ai/pricing#generative_ai_models)) if you use this provider.\n- Associated costs for using Google AI ([see their pricing](https://ai.google.dev/pricing)) if you use this provider.\n\n[Learn more about Firebase billing.](https://firebase.google.com/pricing)\n\n\n\n\n**Configuration Parameters:**\n\n* Gemini API Provider: This extension makes use of the Gemini family of large language models. Currently the extension supports the Google AI Gemini API (for developers) and the Vertex AI Gemini API. Learn more about the differences between the Google AI and Vertex AI Gemini APIs here.\n\n* Gemini model: Input the name of the Gemini model you would like to use. To view available models for each provider, see: [Vertex AI Gemini models](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models), [Google AI Gemini models](https://ai.google.dev/models/gemini)\n\n* Google AI API Key: If you have selected Google AI as your provider, then this parameteris required. If you have instead selected Vertex AI, then this parameter is not required, and application default credentials will be used.\n\n* Firestore Collection Path: Used to store conversation history represented as documents. This extension will listen to the specified collection(s) for new message documents.\n\n* Prompt: This is the text that you want the Gemini API to generate a response for. It can be free-form text or it can use handlebars variables to substitute values from the Firestore document. For example if you set this parameter as \"What is the capital of {{ country }}?\"\n\n* Image field (Gemini Vision Models ONLY): A document field containing a cloud storage URL of an image, or a base64 string of an image. Note that this field is only supported by Gemini, and only with the Gemini Pro Vision models. If you are using a text-only model, you should leave this field blank.\n\n* Response Field: The field in the message document into which to put the response.\n\n* Cloud Functions location: Where do you want to deploy the functions created for this extension? For help selecting a location, refer to the [location selection guide](https://firebase.google.com/docs/functions/locations). Note that Generative AI on Vertex AI is only available in the regions listed [here](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/locations-genai). A list of languages and regions supported by the Gemini API on Google AI is [here](https://ai.google.dev/available_regions).\n\n* Temperature: Controls the randomness of the output. Values can range over [0,1], inclusive. A value closer to 1 will produce responses that are more varied, while a value closer to 0 will typically result in less surprising responses from the model.\n\n* Nucleus sampling probability: If specified, nucleus sampling will be used as the decoding strategy. Nucleus sampling considers the smallest set of tokens whose probability sum is at least a fixed value. Enter a value between 0 and 1.\n\n* Sampling strategy parameter: If specified, top-k sampling will be used as the decoding strategy. Top-k sampling considers the set of topK most probable tokens.\n\n* Candidate count: When set to an integer higher than one, additional candidate responses, up to the specified number, will be stored in Firestore under the 'candidates' field.\n\n* Candidates field: The field in the message document into which to put the other candidate responses if the candidate count parameter is greater than one.\n\n* Hate Speech Threshold: Threshold for hate speech content. Specify what probability level of hate speech content is blocked by the Gemini provider.\n\n* Dangerous Content Threshold: Threshold for dangerous content. Specify what probability level of dangerous content is blocked by the Gemini provider.\n\n* Harassment Content Threshold: Threshold for harassment content. Specify what probability level of harassment content is blocked by the Gemini provider.\n\n* Sexual Content Threshold: Threshold for sexually explicit content. Specify what probability level of sexual content is blocked by the Gemini provider.\n\n\n\n**Cloud Functions:**\n\n* **generateOnCall:** A callable function to perform generative AI tasks.\n\n* **generateText:** Listens to Firestore data writes to perform generative AI tasks.\n\n\n\n**APIs Used**:\n\n* aiplatform.googleapis.com (Reason: For access to the Vertex AI Gemini API if this provider is chosen.)\n\n\n\n**Access Required**:\n\n\n\nThis extension will operate with the following project IAM roles:\n\n* datastore.user (Reason: Allows this extension to access Cloud Firestore to read and process added messages.)\n\n* storage.objectAdmin (Reason: Allows the extension to read from your Cloud Storage.)\n\n* aiplatform.user (Reason: Allows this extension to access the Gemini family of genai models via Vertex AI if this provider is chosen.)\n","displayName":"Multimodal Tasks with the Gemini API","systemParams":[{"param":"firebaseextensions.v1beta.function/timeoutSeconds","label":"Function timeout seconds","type":"STRING","description":"How long should functions run before timing out, in seconds (0-540)?","validationRegex":"^[1-9][0-9]{0,2}$","validationErrorMessage":"Function timeout should be an integer number of seconds, between 0 and 540","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnector","label":"VPC Connector","type":"STRING","description":"The VPC Network Connector that this cloud function can connect to. It can be either the fully-qualified URI, or the short name of the network connector resource. The format of this field is projects/*/locations/*/connectors/*.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/connectors/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/vpcConnectorEgressSettings","label":"VPC Connector Egress settings","type":"SELECT","description":"Controls outgoing traffic when a VPC connector is configured","options":[{"value":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","label":"Unspecified"},{"value":"PRIVATE_RANGES_ONLY","label":"Private ranges only"},{"value":"ALL_TRAFFIC","label":"All traffic"}],"default":"VPC_CONNECTOR_EGRESS_SETTINGS_UNSPECIFIED","advanced":true},{"param":"firebaseextensions.v1beta.function/minInstances","label":"Minimum function instances","type":"STRING","description":"The minimum number of instances of each function to run at once (0-1000)","default":"0","validationRegex":"^[0-9]*$","validationErrorMessage":"Min instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/maxInstances","label":"Maximum function instances","type":"STRING","description":"The maximum number of instances of each function to run at once","validationRegex":"^[0-9]*$","validationErrorMessage":"Max instances must be a non-negative integer.","advanced":true},{"param":"firebaseextensions.v1beta.function/ingressSettings","label":"Function ingress settings","type":"SELECT","description":"Where should functions allow incoming traffic from?","options":[{"value":"ALLOW_ALL","label":"Allow all"},{"value":"ALLOW_INTERNAL_ONLY","label":"Allow internal only"},{"value":"ALLOW_INTERNAL_AND_GCLB","label":"Allow internal and GCLB"}],"advanced":true},{"param":"firebaseextensions.v1beta.function/labels","label":"Function labels","type":"STRING","description":"Do you wish to set any labels on this instance's Cloud Functions? If so, provide up to 55 labels in the format 'key1:value, key2:value'","validationRegex":"^([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63},\\s*)*([a-zžà-ÿ][A-Za-zŽžÀ-ÿ0-9_-]{0,62}:[A-Za-zŽžÀ-ÿ0-9_-]{0,63})$","advanced":true},{"param":"firebaseextensions.v1beta.function/kmsKeyName","label":"KMS key name","type":"STRING","description":"Do you want to use a Customer Managed Encryption Key (CMEK) to encrypt this extension's functions? If you set this, you must also set a Docker repository encrypted by that key. See https://cloud.google.com/functions/docs/securing/cmek for more details.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/keyRings/([^/]+)/cryptoKeys/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/dockerRepository","label":"Docker repository","type":"STRING","description":"What Docker repository should be used to store function images? Default repository will be used if not set.","validationRegex":"^projects/([^/]+)/locations/([^/]+)/repositories/([^/]+)$","advanced":true},{"param":"firebaseextensions.v1beta.function/memory","label":"Function memory","type":"SELECT","description":"How much memory should be allocated to each v1 function?","options":[{"value":"128","label":"128MB"},{"value":"256","label":"256MB"},{"value":"512","label":"512MB"},{"value":"1024","label":"1GB"},{"value":"2048","label":"2GB"},{"value":"4096","label":"4GB"},{"value":"8192","label":"8GB"}],"default":"256","advanced":true}],"icon":"icon.png","tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"]},"state":"PUBLISHED","hash":"85e74b4cf3bc36c01f2d67f4266b051f187f9688e2b84c23c56e2f35a56d677f","createTime":"2024-04-25T15:31:32.490715Z","sourceDownloadUri":"https://storage.googleapis.com/firebase-mod-sources-prod/85e74b4cf3bc36c01f2d67f4266b051f187f9688e2b84c23c56e2f35a56d677f","id":"1.0.0","releaseNotes":"- **Breaking**: made whether IMAGE_FIELDS parameter is defined determine whether the extension calls Gemini with an image.\n\n- Fixed: update dependencies to latest versions, fixes critical protobufjs dependency vulnerability\n\nchore - remove TODO security comment in code\n","buildSourceUri":"https://github.com/googlecloudplatform/firebase-extensions/tree/797ecd86fda524ed7f494985080d5ac03b064e4c","icons":[{"iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_1.0.0@512.png","iconType":"PNG_512"}],"listing":{"state":"APPROVED"},"metrics":{"activeInstallCount":"40"},"tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"],"extensionRoot":"firestore-multimodal-genai"}
[debug] [2024-05-03T17:07:43.323Z] >>> [apiv2][query] GET https://serviceusage.googleapis.com/v1/projects/build-with-ai-js/services/aiplatform.googleapis.com [none]
[debug] [2024-05-03T17:07:43.323Z] >>> [apiv2][(partial)header] GET https://serviceusage.googleapis.com/v1/projects/build-with-ai-js/services/aiplatform.googleapis.com x-goog-quota-user=projects/build-with-ai-js
[debug] [2024-05-03T17:07:44.876Z] <<< [apiv2][status] GET https://serviceusage.googleapis.com/v1/projects/build-with-ai-js/services/aiplatform.googleapis.com 200
[debug] [2024-05-03T17:07:44.877Z] <<< [apiv2][body] GET https://serviceusage.googleapis.com/v1/projects/build-with-ai-js/services/aiplatform.googleapis.com [omitted]
[debug] [2024-05-03T17:07:44.878Z] >>> [apiv2][query] POST https://firebasedynamiclinks.googleapis.com/v1/shortLinks?key=AIzaSyB6PtY5vuiSB8MNgt20mQffkOlunZnHYiQ [none]
[debug] [2024-05-03T17:07:44.878Z] >>> [apiv2][body] POST https://firebasedynamiclinks.googleapis.com/v1/shortLinks?key=AIzaSyB6PtY5vuiSB8MNgt20mQffkOlunZnHYiQ {"dynamicLinkInfo":{"link":"https://console.cloud.google.com/apis/library/aiplatform.googleapis.com?project=build-with-ai-js","domainUriPrefix":"https://firebase.tools/l"},"suffix":{"option":"UNGUESSABLE"}}
[debug] [2024-05-03T17:07:45.765Z] <<< [apiv2][status] POST https://firebasedynamiclinks.googleapis.com/v1/shortLinks?key=AIzaSyB6PtY5vuiSB8MNgt20mQffkOlunZnHYiQ 200
[debug] [2024-05-03T17:07:45.765Z] <<< [apiv2][body] POST https://firebasedynamiclinks.googleapis.com/v1/shortLinks?key=AIzaSyB6PtY5vuiSB8MNgt20mQffkOlunZnHYiQ {"shortLink":"https://firebase.tools/l/5BvLJrULKc6AnSgc8","previewLink":"https://firebase.tools/l/5BvLJrULKc6AnSgc8?d=1"}
[warn] ⚠  Extensions: The following Extensions make calls to Google Cloud APIs that do not have Emulators. These calls will go to production Google Cloud APIs which may have real effects on build-with-ai-js.
┌───────────────────────────┬──────────────────────────┬─────────────────────────────┬────────────────────────────────────────────┐
│ API Name                  │ Instances using this API │ Enabled on build-with-ai-js │ Enable this API                            │
├───────────────────────────┼──────────────────────────┼─────────────────────────────┼────────────────────────────────────────────┤
│ aiplatform.googleapis.com │ firestore-multimodal-ge… │ No                          │ https://firebase.tools/l/5BvLJrULKc6AnSgc8 │
└───────────────────────────┴──────────────────────────┴─────────────────────────────┴────────────────────────────────────────────┘ {"metadata":{"emulator":{"name":"extensions"},"message":"The following Extensions make calls to Google Cloud APIs that do not have Emulators. These calls will go to production Google Cloud APIs which may have real effects on \u001b[1mbuild-with-ai-js\u001b[22m.\n\u001b[90m┌───────────────────────────┬──────────────────────────┬─────────────────────────────┬────────────────────────────────────────────┐\u001b[39m\n\u001b[90m│\u001b[39m\u001b[33m API Name                  \u001b[39m\u001b[90m│\u001b[39m\u001b[33m Instances using this API \u001b[39m\u001b[90m│\u001b[39m\u001b[33m Enabled on build-with-ai-js \u001b[39m\u001b[90m│\u001b[39m\u001b[33m Enable this API                            \u001b[39m\u001b[90m│\u001b[39m\n\u001b[90m├───────────────────────────┼──────────────────────────┼─────────────────────────────┼────────────────────────────────────────────┤\u001b[39m\n\u001b[90m│\u001b[39m aiplatform.googleapis.com \u001b[90m│\u001b[39m firestore-multimodal-ge… \u001b[90m│\u001b[39m No                          \u001b[90m│\u001b[39m \u001b[1m\u001b[4mhttps://firebase.tools/l/5BvLJrULKc6AnSgc8\u001b[24m\u001b[22m \u001b[90m│\u001b[39m\n\u001b[90m└───────────────────────────┴──────────────────────────┴─────────────────────────────┴────────────────────────────────────────────┘\u001b[39m"}}
[info] i  extensions: Starting download for googlecloud/firestore-multimodal-genai@1.0.0 source code to /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0.. {"metadata":{"emulator":{"name":"extensions"},"extension":{"ref":"googlecloud/firestore-multimodal-genai@1.0.0"},"message":"Starting download for googlecloud/firestore-multimodal-genai@1.0.0 source code to /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0.."}}
[info] i  extensions: cache directory for googlecloud/firestore-multimodal-genai@1.0.0 already exists... {"metadata":{"emulator":{"name":"extensions"},"extension":{"ref":"googlecloud/firestore-multimodal-genai@1.0.0"},"message":"cache directory for googlecloud/firestore-multimodal-genai@1.0.0 already exists..."}}
[info] i  extensions: downloading https://storage.googleapis.com/firebase-mod-sources-prod/85e74b4cf3bc36c01f2d67f4266b051f187f9688e2b84c23c56e2f35a56d677f... {"metadata":{"emulator":{"name":"extensions"},"extension":{"ref":"googlecloud/firestore-multimodal-genai@1.0.0"},"message":"downloading https://storage.googleapis.com/firebase-mod-sources-prod/85e74b4cf3bc36c01f2d67f4266b051f187f9688e2b84c23c56e2f35a56d677f..."}}
[debug] [2024-05-03T17:07:45.796Z] >>> [apiv2][query] GET https://storage.googleapis.com/firebase-mod-sources-prod/85e74b4cf3bc36c01f2d67f4266b051f187f9688e2b84c23c56e2f35a56d677f 
[debug] [2024-05-03T17:07:46.687Z] <<< [apiv2][status] GET https://storage.googleapis.com/firebase-mod-sources-prod/85e74b4cf3bc36c01f2d67f4266b051f187f9688e2b84c23c56e2f35a56d677f 200
[debug] [2024-05-03T17:07:46.689Z] <<< [apiv2][body] GET https://storage.googleapis.com/firebase-mod-sources-prod/85e74b4cf3bc36c01f2d67f4266b051f187f9688e2b84c23c56e2f35a56d677f [stream]
[debug] [2024-05-03T17:07:47.721Z] Data is 7469845
[debug] [2024-05-03T17:07:47.721Z] [unzip] Entry: README.md (compressed_size=3739 bytes, uncompressed_size=11264 bytes)
[debug] [2024-05-03T17:07:47.721Z] [unzip] Processing entry: README.md
[debug] [2024-05-03T17:07:47.721Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0
[debug] [2024-05-03T17:07:47.723Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/README.md
[debug] [2024-05-03T17:07:47.728Z] [unzip] Entry: PREINSTALL.md (compressed_size=2498 bytes, uncompressed_size=6454 bytes)
[debug] [2024-05-03T17:07:47.729Z] [unzip] Processing entry: PREINSTALL.md
[debug] [2024-05-03T17:07:47.729Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0
[debug] [2024-05-03T17:07:47.729Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/PREINSTALL.md
[debug] [2024-05-03T17:07:47.731Z] [unzip] Entry: extension.yaml (compressed_size=3822 bytes, uncompressed_size=14568 bytes)
[debug] [2024-05-03T17:07:47.731Z] [unzip] Processing entry: extension.yaml
[debug] [2024-05-03T17:07:47.731Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0
[debug] [2024-05-03T17:07:47.732Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/extension.yaml
[debug] [2024-05-03T17:07:47.733Z] [unzip] Entry: functions/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:07:47.733Z] [unzip] Processing entry: functions/
[debug] [2024-05-03T17:07:47.735Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/
[debug] [2024-05-03T17:07:47.735Z] [unzip] Entry: functions/.gitignore (compressed_size=82 bytes, uncompressed_size=94 bytes)
[debug] [2024-05-03T17:07:47.735Z] [unzip] Processing entry: functions/.gitignore
[debug] [2024-05-03T17:07:47.735Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions
[debug] [2024-05-03T17:07:47.736Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/.gitignore
[debug] [2024-05-03T17:07:47.738Z] [unzip] Entry: functions/__tests__/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:07:47.738Z] [unzip] Processing entry: functions/__tests__/
[debug] [2024-05-03T17:07:47.738Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/
[debug] [2024-05-03T17:07:47.738Z] [unzip] Entry: functions/__tests__/util.ts (compressed_size=353 bytes, uncompressed_size=1750 bytes)
[debug] [2024-05-03T17:07:47.738Z] [unzip] Processing entry: functions/__tests__/util.ts
[debug] [2024-05-03T17:07:47.738Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__
[debug] [2024-05-03T17:07:47.739Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/util.ts
[debug] [2024-05-03T17:07:47.744Z] [unzip] Entry: functions/__tests__/google_ai/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:07:47.744Z] [unzip] Processing entry: functions/__tests__/google_ai/
[debug] [2024-05-03T17:07:47.744Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/google_ai/
[debug] [2024-05-03T17:07:47.745Z] [unzip] Entry: functions/__tests__/google_ai/images.test.ts (compressed_size=2796 bytes, uncompressed_size=11693 bytes)
[debug] [2024-05-03T17:07:47.745Z] [unzip] Processing entry: functions/__tests__/google_ai/images.test.ts
[debug] [2024-05-03T17:07:47.745Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/google_ai
[debug] [2024-05-03T17:07:47.745Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/google_ai/images.test.ts
[debug] [2024-05-03T17:07:47.746Z] [unzip] Entry: functions/__tests__/google_ai/index.test.ts (compressed_size=2530 bytes, uncompressed_size=9813 bytes)
[debug] [2024-05-03T17:07:47.746Z] [unzip] Processing entry: functions/__tests__/google_ai/index.test.ts
[debug] [2024-05-03T17:07:47.746Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/google_ai
[debug] [2024-05-03T17:07:47.746Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/google_ai/index.test.ts
[debug] [2024-05-03T17:07:47.747Z] [unzip] Entry: functions/__tests__/fixtures/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:07:47.747Z] [unzip] Processing entry: functions/__tests__/fixtures/
[debug] [2024-05-03T17:07:47.747Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/fixtures/
[debug] [2024-05-03T17:07:47.747Z] [unzip] Entry: functions/__tests__/fixtures/imageMock.ts (compressed_size=3276 bytes, uncompressed_size=5122 bytes)
[debug] [2024-05-03T17:07:47.747Z] [unzip] Processing entry: functions/__tests__/fixtures/imageMock.ts
[debug] [2024-05-03T17:07:47.747Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/fixtures
[debug] [2024-05-03T17:07:47.747Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/fixtures/imageMock.ts
[debug] [2024-05-03T17:07:47.748Z] [unzip] Entry: functions/__tests__/fixtures/large-image.jpg (compressed_size=7292539 bytes, uncompressed_size=7330166 bytes)
[debug] [2024-05-03T17:07:47.748Z] [unzip] Processing entry: functions/__tests__/fixtures/large-image.jpg
[debug] [2024-05-03T17:07:47.748Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/fixtures
[debug] [2024-05-03T17:07:47.749Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/fixtures/large-image.jpg
[debug] [2024-05-03T17:07:47.802Z] [unzip] Entry: functions/__tests__/vertex_ai/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:07:47.802Z] [unzip] Processing entry: functions/__tests__/vertex_ai/
[debug] [2024-05-03T17:07:47.802Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/vertex_ai/
[debug] [2024-05-03T17:07:47.802Z] [unzip] Entry: functions/__tests__/vertex_ai/images.test.ts (compressed_size=2707 bytes, uncompressed_size=10412 bytes)
[debug] [2024-05-03T17:07:47.802Z] [unzip] Processing entry: functions/__tests__/vertex_ai/images.test.ts
[debug] [2024-05-03T17:07:47.802Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/vertex_ai
[debug] [2024-05-03T17:07:47.803Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/vertex_ai/images.test.ts
[debug] [2024-05-03T17:07:47.804Z] [unzip] Entry: functions/__tests__/vertex_ai/index.test.ts (compressed_size=2546 bytes, uncompressed_size=9656 bytes)
[debug] [2024-05-03T17:07:47.804Z] [unzip] Processing entry: functions/__tests__/vertex_ai/index.test.ts
[debug] [2024-05-03T17:07:47.804Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/vertex_ai
[debug] [2024-05-03T17:07:47.804Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/__tests__/vertex_ai/index.test.ts
[debug] [2024-05-03T17:07:47.805Z] [unzip] Entry: functions/lib/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:07:47.805Z] [unzip] Processing entry: functions/lib/
[debug] [2024-05-03T17:07:47.805Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/
[debug] [2024-05-03T17:07:47.806Z] [unzip] Entry: functions/lib/errors.js.map (compressed_size=499 bytes, uncompressed_size=1172 bytes)
[debug] [2024-05-03T17:07:47.806Z] [unzip] Processing entry: functions/lib/errors.js.map
[debug] [2024-05-03T17:07:47.806Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib
[debug] [2024-05-03T17:07:47.806Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/errors.js.map
[debug] [2024-05-03T17:07:47.807Z] [unzip] Entry: functions/lib/config.js.map (compressed_size=683 bytes, uncompressed_size=2316 bytes)
[debug] [2024-05-03T17:07:47.807Z] [unzip] Processing entry: functions/lib/config.js.map
[debug] [2024-05-03T17:07:47.807Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib
[debug] [2024-05-03T17:07:47.807Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/config.js.map
[debug] [2024-05-03T17:07:47.808Z] [unzip] Entry: functions/lib/types.js (compressed_size=569 bytes, uncompressed_size=1073 bytes)
[debug] [2024-05-03T17:07:47.808Z] [unzip] Processing entry: functions/lib/types.js
[debug] [2024-05-03T17:07:47.808Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib
[debug] [2024-05-03T17:07:47.808Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/types.js
[debug] [2024-05-03T17:07:47.809Z] [unzip] Entry: functions/lib/index.js (compressed_size=1898 bytes, uncompressed_size=6526 bytes)
[debug] [2024-05-03T17:07:47.809Z] [unzip] Processing entry: functions/lib/index.js
[debug] [2024-05-03T17:07:47.809Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib
[debug] [2024-05-03T17:07:47.809Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/index.js
[debug] [2024-05-03T17:07:47.810Z] [unzip] Entry: functions/lib/logs.js.map (compressed_size=452 bytes, uncompressed_size=1141 bytes)
[debug] [2024-05-03T17:07:47.810Z] [unzip] Processing entry: functions/lib/logs.js.map
[debug] [2024-05-03T17:07:47.810Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib
[debug] [2024-05-03T17:07:47.810Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/logs.js.map
[debug] [2024-05-03T17:07:47.810Z] [unzip] Entry: functions/lib/generative-client/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:07:47.811Z] [unzip] Processing entry: functions/lib/generative-client/
[debug] [2024-05-03T17:07:47.811Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client/
[debug] [2024-05-03T17:07:47.811Z] [unzip] Entry: functions/lib/generative-client/generative_ai.js (compressed_size=1149 bytes, uncompressed_size=3219 bytes)
[debug] [2024-05-03T17:07:47.811Z] [unzip] Processing entry: functions/lib/generative-client/generative_ai.js
[debug] [2024-05-03T17:07:47.811Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client
[debug] [2024-05-03T17:07:47.811Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client/generative_ai.js
[debug] [2024-05-03T17:07:47.812Z] [unzip] Entry: functions/lib/generative-client/generative_language.js.map (compressed_size=878 bytes, uncompressed_size=2661 bytes)
[debug] [2024-05-03T17:07:47.812Z] [unzip] Processing entry: functions/lib/generative-client/generative_language.js.map
[debug] [2024-05-03T17:07:47.812Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client
[debug] [2024-05-03T17:07:47.812Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client/generative_language.js.map
[debug] [2024-05-03T17:07:47.812Z] [unzip] Entry: functions/lib/generative-client/generative_language.js (compressed_size=1199 bytes, uncompressed_size=3699 bytes)
[debug] [2024-05-03T17:07:47.813Z] [unzip] Processing entry: functions/lib/generative-client/generative_language.js
[debug] [2024-05-03T17:07:47.813Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client
[debug] [2024-05-03T17:07:47.813Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client/generative_language.js
[debug] [2024-05-03T17:07:47.813Z] [unzip] Entry: functions/lib/generative-client/image_utils.js (compressed_size=1210 bytes, uncompressed_size=3748 bytes)
[debug] [2024-05-03T17:07:47.813Z] [unzip] Processing entry: functions/lib/generative-client/image_utils.js
[debug] [2024-05-03T17:07:47.814Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client
[debug] [2024-05-03T17:07:47.814Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client/image_utils.js
[debug] [2024-05-03T17:07:47.814Z] [unzip] Entry: functions/lib/generative-client/index.js (compressed_size=407 bytes, uncompressed_size=1190 bytes)
[debug] [2024-05-03T17:07:47.814Z] [unzip] Processing entry: functions/lib/generative-client/index.js
[debug] [2024-05-03T17:07:47.814Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client
[debug] [2024-05-03T17:07:47.814Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client/index.js
[debug] [2024-05-03T17:07:47.815Z] [unzip] Entry: functions/lib/generative-client/generative_ai.js.map (compressed_size=791 bytes, uncompressed_size=2155 bytes)
[debug] [2024-05-03T17:07:47.815Z] [unzip] Processing entry: functions/lib/generative-client/generative_ai.js.map
[debug] [2024-05-03T17:07:47.815Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client
[debug] [2024-05-03T17:07:47.815Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client/generative_ai.js.map
[debug] [2024-05-03T17:07:47.816Z] [unzip] Entry: functions/lib/generative-client/image_utils.js.map (compressed_size=904 bytes, uncompressed_size=3210 bytes)
[debug] [2024-05-03T17:07:47.816Z] [unzip] Processing entry: functions/lib/generative-client/image_utils.js.map
[debug] [2024-05-03T17:07:47.816Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client
[debug] [2024-05-03T17:07:47.816Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client/image_utils.js.map
[debug] [2024-05-03T17:07:47.817Z] [unzip] Entry: functions/lib/generative-client/base_client.js (compressed_size=221 bytes, uncompressed_size=339 bytes)
[debug] [2024-05-03T17:07:47.817Z] [unzip] Processing entry: functions/lib/generative-client/base_client.js
[debug] [2024-05-03T17:07:47.817Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client
[debug] [2024-05-03T17:07:47.817Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client/base_client.js
[debug] [2024-05-03T17:07:47.817Z] [unzip] Entry: functions/lib/generative-client/index.js.map (compressed_size=334 bytes, uncompressed_size=825 bytes)
[debug] [2024-05-03T17:07:47.817Z] [unzip] Processing entry: functions/lib/generative-client/index.js.map
[debug] [2024-05-03T17:07:47.817Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client
[debug] [2024-05-03T17:07:47.818Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client/index.js.map
[debug] [2024-05-03T17:07:47.819Z] [unzip] Entry: functions/lib/generative-client/base_client.js.map (compressed_size=194 bytes, uncompressed_size=286 bytes)
[debug] [2024-05-03T17:07:47.819Z] [unzip] Processing entry: functions/lib/generative-client/base_client.js.map
[debug] [2024-05-03T17:07:47.819Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client
[debug] [2024-05-03T17:07:47.819Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client/base_client.js.map
[debug] [2024-05-03T17:07:47.819Z] [unzip] Entry: functions/lib/generative-client/vertex_ai.js.map (compressed_size=884 bytes, uncompressed_size=2566 bytes)
[debug] [2024-05-03T17:07:47.819Z] [unzip] Processing entry: functions/lib/generative-client/vertex_ai.js.map
[debug] [2024-05-03T17:07:47.819Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client
[debug] [2024-05-03T17:07:47.819Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client/vertex_ai.js.map
[debug] [2024-05-03T17:07:47.820Z] [unzip] Entry: functions/lib/generative-client/vertex_ai.js (compressed_size=1236 bytes, uncompressed_size=3582 bytes)
[debug] [2024-05-03T17:07:47.820Z] [unzip] Processing entry: functions/lib/generative-client/vertex_ai.js
[debug] [2024-05-03T17:07:47.820Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client
[debug] [2024-05-03T17:07:47.820Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/generative-client/vertex_ai.js
[debug] [2024-05-03T17:07:47.821Z] [unzip] Entry: functions/lib/config.js (compressed_size=979 bytes, uncompressed_size=2686 bytes)
[debug] [2024-05-03T17:07:47.821Z] [unzip] Processing entry: functions/lib/config.js
[debug] [2024-05-03T17:07:47.821Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib
[debug] [2024-05-03T17:07:47.821Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/config.js
[debug] [2024-05-03T17:07:47.821Z] [unzip] Entry: functions/lib/utils.js.map (compressed_size=455 bytes, uncompressed_size=1182 bytes)
[debug] [2024-05-03T17:07:47.821Z] [unzip] Processing entry: functions/lib/utils.js.map
[debug] [2024-05-03T17:07:47.821Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib
[debug] [2024-05-03T17:07:47.821Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/utils.js.map
[debug] [2024-05-03T17:07:47.822Z] [unzip] Entry: functions/lib/utils.js (compressed_size=546 bytes, uncompressed_size=1401 bytes)
[debug] [2024-05-03T17:07:47.822Z] [unzip] Processing entry: functions/lib/utils.js
[debug] [2024-05-03T17:07:47.822Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib
[debug] [2024-05-03T17:07:47.822Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/utils.js
[debug] [2024-05-03T17:07:47.822Z] [unzip] Entry: functions/lib/errors.js (compressed_size=755 bytes, uncompressed_size=2057 bytes)
[debug] [2024-05-03T17:07:47.822Z] [unzip] Processing entry: functions/lib/errors.js
[debug] [2024-05-03T17:07:47.822Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib
[debug] [2024-05-03T17:07:47.823Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/errors.js
[debug] [2024-05-03T17:07:47.823Z] [unzip] Entry: functions/lib/index.js.map (compressed_size=1221 bytes, uncompressed_size=4613 bytes)
[debug] [2024-05-03T17:07:47.823Z] [unzip] Processing entry: functions/lib/index.js.map
[debug] [2024-05-03T17:07:47.823Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib
[debug] [2024-05-03T17:07:47.823Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/index.js.map
[debug] [2024-05-03T17:07:47.824Z] [unzip] Entry: functions/lib/logs.js (compressed_size=979 bytes, uncompressed_size=2246 bytes)
[debug] [2024-05-03T17:07:47.824Z] [unzip] Processing entry: functions/lib/logs.js
[debug] [2024-05-03T17:07:47.824Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib
[debug] [2024-05-03T17:07:47.824Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/logs.js
[debug] [2024-05-03T17:07:47.824Z] [unzip] Entry: functions/lib/types.js.map (compressed_size=176 bytes, uncompressed_size=345 bytes)
[debug] [2024-05-03T17:07:47.824Z] [unzip] Processing entry: functions/lib/types.js.map
[debug] [2024-05-03T17:07:47.824Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib
[debug] [2024-05-03T17:07:47.824Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/lib/types.js.map
[debug] [2024-05-03T17:07:47.825Z] [unzip] Entry: functions/jest.config.json (compressed_size=126 bytes, uncompressed_size=196 bytes)
[debug] [2024-05-03T17:07:47.825Z] [unzip] Processing entry: functions/jest.config.json
[debug] [2024-05-03T17:07:47.825Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions
[debug] [2024-05-03T17:07:47.825Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/jest.config.json
[debug] [2024-05-03T17:07:47.826Z] [unzip] Entry: functions/jest.setup.ts (compressed_size=122 bytes, uncompressed_size=217 bytes)
[debug] [2024-05-03T17:07:47.826Z] [unzip] Processing entry: functions/jest.setup.ts
[debug] [2024-05-03T17:07:47.826Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions
[debug] [2024-05-03T17:07:47.826Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/jest.setup.ts
[debug] [2024-05-03T17:07:47.826Z] [unzip] Entry: functions/tsconfig.json (compressed_size=184 bytes, uncompressed_size=306 bytes)
[debug] [2024-05-03T17:07:47.826Z] [unzip] Processing entry: functions/tsconfig.json
[debug] [2024-05-03T17:07:47.826Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions
[debug] [2024-05-03T17:07:47.827Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/tsconfig.json
[debug] [2024-05-03T17:07:47.827Z] [unzip] Entry: functions/package.json (compressed_size=645 bytes, uncompressed_size=1573 bytes)
[debug] [2024-05-03T17:07:47.827Z] [unzip] Processing entry: functions/package.json
[debug] [2024-05-03T17:07:47.827Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions
[debug] [2024-05-03T17:07:47.827Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/package.json
[debug] [2024-05-03T17:07:47.828Z] [unzip] Entry: functions/src/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:07:47.828Z] [unzip] Processing entry: functions/src/
[debug] [2024-05-03T17:07:47.828Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/
[debug] [2024-05-03T17:07:47.828Z] [unzip] Entry: functions/src/index.ts (compressed_size=1919 bytes, uncompressed_size=6174 bytes)
[debug] [2024-05-03T17:07:47.828Z] [unzip] Processing entry: functions/src/index.ts
[debug] [2024-05-03T17:07:47.828Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src
[debug] [2024-05-03T17:07:47.828Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/index.ts
[debug] [2024-05-03T17:07:47.829Z] [unzip] Entry: functions/src/__mocks__/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:07:47.829Z] [unzip] Processing entry: functions/src/__mocks__/
[debug] [2024-05-03T17:07:47.829Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/__mocks__/
[debug] [2024-05-03T17:07:47.829Z] [unzip] Entry: functions/src/__mocks__/config.ts (compressed_size=279 bytes, uncompressed_size=530 bytes)
[debug] [2024-05-03T17:07:47.829Z] [unzip] Processing entry: functions/src/__mocks__/config.ts
[debug] [2024-05-03T17:07:47.829Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/__mocks__
[debug] [2024-05-03T17:07:47.830Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/__mocks__/config.ts
[debug] [2024-05-03T17:07:47.830Z] [unzip] Entry: functions/src/utils.ts (compressed_size=477 bytes, uncompressed_size=1115 bytes)
[debug] [2024-05-03T17:07:47.830Z] [unzip] Processing entry: functions/src/utils.ts
[debug] [2024-05-03T17:07:47.830Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src
[debug] [2024-05-03T17:07:47.830Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/utils.ts
[debug] [2024-05-03T17:07:47.831Z] [unzip] Entry: functions/src/errors.ts (compressed_size=1001 bytes, uncompressed_size=2237 bytes)
[debug] [2024-05-03T17:07:47.831Z] [unzip] Processing entry: functions/src/errors.ts
[debug] [2024-05-03T17:07:47.831Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src
[debug] [2024-05-03T17:07:47.831Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/errors.ts
[debug] [2024-05-03T17:07:47.832Z] [unzip] Entry: functions/src/utils.test.ts (compressed_size=890 bytes, uncompressed_size=3947 bytes)
[debug] [2024-05-03T17:07:47.832Z] [unzip] Processing entry: functions/src/utils.test.ts
[debug] [2024-05-03T17:07:47.832Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src
[debug] [2024-05-03T17:07:47.832Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/utils.test.ts
[debug] [2024-05-03T17:07:47.832Z] [unzip] Entry: functions/src/types.ts (compressed_size=613 bytes, uncompressed_size=1748 bytes)
[debug] [2024-05-03T17:07:47.833Z] [unzip] Processing entry: functions/src/types.ts
[debug] [2024-05-03T17:07:47.833Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src
[debug] [2024-05-03T17:07:47.833Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/types.ts
[debug] [2024-05-03T17:07:47.833Z] [unzip] Entry: functions/src/generative-client/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:07:47.833Z] [unzip] Processing entry: functions/src/generative-client/
[debug] [2024-05-03T17:07:47.833Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/generative-client/
[debug] [2024-05-03T17:07:47.833Z] [unzip] Entry: functions/src/generative-client/index.ts (compressed_size=412 bytes, uncompressed_size=1248 bytes)
[debug] [2024-05-03T17:07:47.833Z] [unzip] Processing entry: functions/src/generative-client/index.ts
[debug] [2024-05-03T17:07:47.834Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/generative-client
[debug] [2024-05-03T17:07:47.834Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/generative-client/index.ts
[debug] [2024-05-03T17:07:47.834Z] [unzip] Entry: functions/src/generative-client/image_utils.test.ts (compressed_size=502 bytes, uncompressed_size=1572 bytes)
[debug] [2024-05-03T17:07:47.834Z] [unzip] Processing entry: functions/src/generative-client/image_utils.test.ts
[debug] [2024-05-03T17:07:47.834Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/generative-client
[debug] [2024-05-03T17:07:47.834Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/generative-client/image_utils.test.ts
[debug] [2024-05-03T17:07:47.835Z] [unzip] Entry: functions/src/generative-client/base_client.ts (compressed_size=247 bytes, uncompressed_size=415 bytes)
[debug] [2024-05-03T17:07:47.835Z] [unzip] Processing entry: functions/src/generative-client/base_client.ts
[debug] [2024-05-03T17:07:47.835Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/generative-client
[debug] [2024-05-03T17:07:47.835Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/generative-client/base_client.ts
[debug] [2024-05-03T17:07:47.836Z] [unzip] Entry: functions/src/generative-client/vertex_ai.ts (compressed_size=1120 bytes, uncompressed_size=2890 bytes)
[debug] [2024-05-03T17:07:47.836Z] [unzip] Processing entry: functions/src/generative-client/vertex_ai.ts
[debug] [2024-05-03T17:07:47.836Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/generative-client
[debug] [2024-05-03T17:07:47.836Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/generative-client/vertex_ai.ts
[debug] [2024-05-03T17:07:47.836Z] [unzip] Entry: functions/src/generative-client/generative_language.ts (compressed_size=1110 bytes, uncompressed_size=3044 bytes)
[debug] [2024-05-03T17:07:47.836Z] [unzip] Processing entry: functions/src/generative-client/generative_language.ts
[debug] [2024-05-03T17:07:47.836Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/generative-client
[debug] [2024-05-03T17:07:47.836Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/generative-client/generative_language.ts
[debug] [2024-05-03T17:07:47.837Z] [unzip] Entry: functions/src/generative-client/image_utils.ts (compressed_size=1140 bytes, uncompressed_size=3238 bytes)
[debug] [2024-05-03T17:07:47.837Z] [unzip] Processing entry: functions/src/generative-client/image_utils.ts
[debug] [2024-05-03T17:07:47.837Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/generative-client
[debug] [2024-05-03T17:07:47.837Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/generative-client/image_utils.ts
[debug] [2024-05-03T17:07:47.838Z] [unzip] Entry: functions/src/generative-client/generative_ai.ts (compressed_size=1025 bytes, uncompressed_size=2592 bytes)
[debug] [2024-05-03T17:07:47.838Z] [unzip] Processing entry: functions/src/generative-client/generative_ai.ts
[debug] [2024-05-03T17:07:47.838Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/generative-client
[debug] [2024-05-03T17:07:47.838Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/generative-client/generative_ai.ts
[debug] [2024-05-03T17:07:47.838Z] [unzip] Entry: functions/src/logs.ts (compressed_size=864 bytes, uncompressed_size=1792 bytes)
[debug] [2024-05-03T17:07:47.838Z] [unzip] Processing entry: functions/src/logs.ts
[debug] [2024-05-03T17:07:47.839Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src
[debug] [2024-05-03T17:07:47.839Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/logs.ts
[debug] [2024-05-03T17:07:47.839Z] [unzip] Entry: functions/src/config.ts (compressed_size=1395 bytes, uncompressed_size=3672 bytes)
[debug] [2024-05-03T17:07:47.839Z] [unzip] Processing entry: functions/src/config.ts
[debug] [2024-05-03T17:07:47.839Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src
[debug] [2024-05-03T17:07:47.839Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/config.ts
[debug] [2024-05-03T17:07:47.840Z] [unzip] Entry: functions/src/logs.test.ts (compressed_size=677 bytes, uncompressed_size=2103 bytes)
[debug] [2024-05-03T17:07:47.840Z] [unzip] Processing entry: functions/src/logs.test.ts
[debug] [2024-05-03T17:07:47.840Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src
[debug] [2024-05-03T17:07:47.840Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/src/logs.test.ts
[debug] [2024-05-03T17:07:47.840Z] [unzip] Entry: functions/package-lock.json (compressed_size=90619 bytes, uncompressed_size=360077 bytes)
[debug] [2024-05-03T17:07:47.840Z] [unzip] Processing entry: functions/package-lock.json
[debug] [2024-05-03T17:07:47.841Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions
[debug] [2024-05-03T17:07:47.841Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/package-lock.json
[debug] [2024-05-03T17:07:47.843Z] [unzip] Entry: functions/tsconfig.build.json (compressed_size=111 bytes, uncompressed_size=187 bytes)
[debug] [2024-05-03T17:07:47.843Z] [unzip] Processing entry: functions/tsconfig.build.json
[debug] [2024-05-03T17:07:47.843Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions
[debug] [2024-05-03T17:07:47.843Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions/tsconfig.build.json
[debug] [2024-05-03T17:07:47.844Z] [unzip] Entry: CHANGELOG.md (compressed_size=506 bytes, uncompressed_size=1023 bytes)
[debug] [2024-05-03T17:07:47.844Z] [unzip] Processing entry: CHANGELOG.md
[debug] [2024-05-03T17:07:47.844Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0
[debug] [2024-05-03T17:07:47.844Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/CHANGELOG.md
[debug] [2024-05-03T17:07:47.844Z] [unzip] Entry: POSTINSTALL.md (compressed_size=1463 bytes, uncompressed_size=3362 bytes)
[debug] [2024-05-03T17:07:47.844Z] [unzip] Processing entry: POSTINSTALL.md
[debug] [2024-05-03T17:07:47.845Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0
[debug] [2024-05-03T17:07:47.845Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/POSTINSTALL.md
[debug] [2024-05-03T17:07:47.845Z] [unzip] Entry: icon.png (compressed_size=13551 bytes, uncompressed_size=14069 bytes)
[debug] [2024-05-03T17:07:47.845Z] [unzip] Processing entry: icon.png
[debug] [2024-05-03T17:07:47.845Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0
[debug] [2024-05-03T17:07:47.845Z] [unzip] deflating: /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/icon.png
[info] i  extensions: Downloaded to /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0... {"metadata":{"emulator":{"name":"extensions"},"extension":{"ref":"googlecloud/firestore-multimodal-genai@1.0.0"},"message":"Downloaded to /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0..."}}
[debug] [2024-05-03T17:07:48.849Z] [Extensions] Running "npm install" for /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0
[debug] [2024-05-03T17:07:57.769Z] [Extensions] Finished "npm install" for /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0
[debug] [2024-05-03T17:07:57.769Z] [Extensions] Running "npm run gcp-build" for /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0
[debug] [2024-05-03T17:07:58.052Z] [Extensions] Finished "npm run gcp-build" for /home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0
[warn] ⚠  Function 'generateOnCall is missing a trigger in extension.yaml. Please add one, as triggers defined in code are ignored. {"metadata":{"emulator":{"name":"functions"},"message":"Function 'generateOnCall is missing a trigger in extension.yaml. Please add one, as triggers defined in code are ignored."}}
[debug] [2024-05-03T17:07:58.054Z] >>> [apiv2][query] GET https://firebaseextensions.googleapis.com/v1beta/publishers/googlecloud/extensions/firestore-multimodal-genai [none]
[debug] [2024-05-03T17:07:59.283Z] <<< [apiv2][status] GET https://firebaseextensions.googleapis.com/v1beta/publishers/googlecloud/extensions/firestore-multimodal-genai 200
[debug] [2024-05-03T17:07:59.284Z] <<< [apiv2][body] GET https://firebaseextensions.googleapis.com/v1beta/publishers/googlecloud/extensions/firestore-multimodal-genai {"name":"publishers/googlecloud/extensions/firestore-multimodal-genai","ref":"googlecloud/firestore-multimodal-genai","latestVersion":"1.0.0","latestVersionCreateTime":"2024-04-25T15:31:32.490715Z","state":"PUBLISHED","createTime":"2023-12-14T21:15:44.662535Z","iconUri":"https://storage.googleapis.com/firebase-extensions-icons/extension_icons/googlecloud/firestore-multimodal-genai_1.0.0@512.png","publisher":{"displayName":"Google Cloud","iconUri":"https://storage.googleapis.com/firebase-extensions-icons/publisher_icons/googlecloud/google-cloud-icon.png"},"repoUri":"https://github.com/googlecloudplatform/firebase-extensions","metrics":{"activeInstallCount":"300"},"tags":["ai","generative-ai","text-ai","generative-ai","vertex-ai","generative-models","llm","nlp","google-ai"],"latestApprovedVersion":"1.0.0"}
[debug] [2024-05-03T17:07:59.294Z] [functions] Functions Emulator only supports listening on one address (127.0.0.1). Not listening on ::1
[debug] [2024-05-03T17:07:59.294Z] [eventarc] Eventarc Emulator only supports listening on one address (127.0.0.1). Not listening on ::1
[debug] [2024-05-03T17:07:59.294Z] [logging] Logging Emulator only supports listening on one address (127.0.0.1). Not listening on ::1
[debug] [2024-05-03T17:07:59.294Z] [auth] Authentication Emulator only supports listening on one address (127.0.0.1). Not listening on ::1
[debug] [2024-05-03T17:07:59.294Z] [firestore] Firestore Emulator only supports listening on one address (127.0.0.1). Not listening on ::1
[debug] [2024-05-03T17:07:59.294Z] [firestore.websocket] websocket server for firestore only supports listening on one address (127.0.0.1). Not listening on ::1
[debug] [2024-05-03T17:07:59.294Z] [hosting] Hosting Emulator only supports listening on one address (127.0.0.1). Not listening on ::1
[debug] [2024-05-03T17:07:59.294Z] assigned listening specs for emulators {"user":{"functions":[{"address":"127.0.0.1","family":"IPv4","port":5001}],"eventarc":[{"address":"127.0.0.1","family":"IPv4","port":9299}],"hub":[{"address":"127.0.0.1","family":"IPv4","port":4400},{"address":"::1","family":"IPv6","port":4400}],"ui":[{"address":"127.0.0.1","family":"IPv4","port":4000},{"address":"::1","family":"IPv6","port":4000}],"logging":[{"address":"127.0.0.1","family":"IPv4","port":4500}],"auth":[{"address":"127.0.0.1","family":"IPv4","port":9099}],"firestore":[{"address":"127.0.0.1","family":"IPv4","port":8080}],"firestore.websocket":[{"address":"127.0.0.1","family":"IPv4","port":9150}],"hosting":[{"address":"127.0.0.1","family":"IPv4","port":5000}]},"metadata":{"message":"assigned listening specs for emulators"}}
[debug] [2024-05-03T17:07:59.300Z] [hub] writing locator at /tmp/hub-build-with-ai-js.json
[warn] ⚠  functions: The functions emulator is configured but there is no functions source directory. Have you run firebase init functions? {"metadata":{"emulator":{"name":"functions"},"message":"The functions emulator is configured but there is no functions source directory. Have you run \u001b[1mfirebase init functions\u001b[22m?"}}
[debug] [2024-05-03T17:07:59.305Z] [Extensions] Started Extensions emulator, this is a noop.
[warn] ⚠  functions: The following emulators are not running, calls to these services from the Functions emulator will affect production: database, pubsub, storage, dataconnect {"metadata":{"emulator":{"name":"functions"},"message":"The following emulators are not running, calls to these services from the Functions emulator will affect production: \u001b[1mdatabase, pubsub, storage, dataconnect\u001b[22m"}}
[debug] [2024-05-03T17:07:59.307Z] defaultcredentials: writing to file /home/edupsousa/.config/firebase/edupsousa_gmail_com_application_default_credentials.json
[debug] [2024-05-03T17:07:59.321Z] Setting GAC to /home/edupsousa/.config/firebase/edupsousa_gmail_com_application_default_credentials.json {"metadata":{"emulator":{"name":"functions"},"message":"Setting GAC to /home/edupsousa/.config/firebase/edupsousa_gmail_com_application_default_credentials.json"}}
[debug] [2024-05-03T17:07:59.322Z] >>> [apiv2][query] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js/adminSdkConfig [none]
[debug] [2024-05-03T17:07:59.894Z] <<< [apiv2][status] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js/adminSdkConfig 200
[debug] [2024-05-03T17:07:59.895Z] <<< [apiv2][body] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js/adminSdkConfig {"projectId":"build-with-ai-js","storageBucket":"build-with-ai-js.appspot.com"}
[debug] [2024-05-03T17:07:59.929Z] Ignoring unsupported arg: auto_download {"metadata":{"emulator":{"name":"firestore"},"message":"Ignoring unsupported arg: auto_download"}}
[debug] [2024-05-03T17:07:59.929Z] Ignoring unsupported arg: single_project_mode_error {"metadata":{"emulator":{"name":"firestore"},"message":"Ignoring unsupported arg: single_project_mode_error"}}
[debug] [2024-05-03T17:07:59.929Z] Starting Firestore Emulator with command {"binary":"java","args":["-Dgoogle.cloud_firestore.debug_log_level=FINE","-Duser.language=en","-jar","/home/edupsousa/.cache/firebase/emulators/cloud-firestore-emulator-v1.19.5.jar","--host","127.0.0.1","--port",8080,"--websocket_port",9150,"--project_id","build-with-ai-js","--rules","/home/edupsousa/projects/build-with-ai-js/config/firestore.rules","--single_project_mode",true,"--functions_emulator","127.0.0.1:5001"],"optionalArgs":["port","webchannel_port","host","rules","websocket_port","functions_emulator","seed_from_export","project_id","single_project_mode"],"joinArgs":false,"shell":false} {"metadata":{"emulator":{"name":"firestore"},"message":"Starting Firestore Emulator with command {\"binary\":\"java\",\"args\":[\"-Dgoogle.cloud_firestore.debug_log_level=FINE\",\"-Duser.language=en\",\"-jar\",\"/home/edupsousa/.cache/firebase/emulators/cloud-firestore-emulator-v1.19.5.jar\",\"--host\",\"127.0.0.1\",\"--port\",8080,\"--websocket_port\",9150,\"--project_id\",\"build-with-ai-js\",\"--rules\",\"/home/edupsousa/projects/build-with-ai-js/config/firestore.rules\",\"--single_project_mode\",true,\"--functions_emulator\",\"127.0.0.1:5001\"],\"optionalArgs\":[\"port\",\"webchannel_port\",\"host\",\"rules\",\"websocket_port\",\"functions_emulator\",\"seed_from_export\",\"project_id\",\"single_project_mode\"],\"joinArgs\":false,\"shell\":false}"}}
[info] i  firestore: Firestore Emulator logging to firestore-debug.log {"metadata":{"emulator":{"name":"firestore"},"message":"Firestore Emulator logging to \u001b[1mfirestore-debug.log\u001b[22m"}}
[debug] [2024-05-03T17:08:01.000Z] May 03, 2024 2:08:00 PM com.google.cloud.datastore.emulator.firestore.websocket.WebSocketServer start
INFO: Started WebSocket server on ws://127.0.0.1:9150
 {"metadata":{"emulator":{"name":"firestore"},"message":"May 03, 2024 2:08:00 PM com.google.cloud.datastore.emulator.firestore.websocket.WebSocketServer start\nINFO: Started WebSocket server on ws://127.0.0.1:9150\n"}}
[debug] [2024-05-03T17:08:01.032Z] API endpoint: http:// {"metadata":{"emulator":{"name":"firestore"},"message":"API endpoint: http://"}}
[debug] [2024-05-03T17:08:01.032Z] 127.0.0.1:8080
If you are using a library that supports the FIRESTORE_EMULATOR_HOST environment variable, run:

   export FIRESTORE_EMULATOR_HOST=127.0.0.1:8080

If you are running a Firestore in Datastore Mode project, run:

   export DATASTORE_EMULATOR_HOST=127.0.0.1:8080

Note: Support for Datastore Mode is in preview. If you encounter any bugs please file at https://github.com/firebase/firebase-tools/issues.
Dev App Server is now running.

 {"metadata":{"emulator":{"name":"firestore"},"message":"127.0.0.1:8080\nIf you are using a library that supports the FIRESTORE_EMULATOR_HOST environment variable, run:\n\n   export FIRESTORE_EMULATOR_HOST=127.0.0.1:8080\n\nIf you are running a Firestore in Datastore Mode project, run:\n\n   export DATASTORE_EMULATOR_HOST=127.0.0.1:8080\n\nNote: Support for Datastore Mode is in preview. If you encounter any bugs please file at https://github.com/firebase/firebase-tools/issues.\nDev App Server is now running.\n\n"}}
[info] ✔  firestore: Firestore Emulator UI websocket is running on 9150. {"metadata":{"emulator":{"name":"firestore"},"message":"Firestore Emulator UI websocket is running on 9150."}}
[debug] [2024-05-03T17:08:07.843Z] >>> [apiv2][query] GET https://firebasehosting.googleapis.com/v1beta1/projects/build-with-ai-js/sites 
[debug] [2024-05-03T17:08:09.728Z] <<< [apiv2][status] GET https://firebasehosting.googleapis.com/v1beta1/projects/build-with-ai-js/sites 200
[debug] [2024-05-03T17:08:09.729Z] <<< [apiv2][body] GET https://firebasehosting.googleapis.com/v1beta1/projects/build-with-ai-js/sites {"sites":[{"name":"projects/build-with-ai-js/sites/build-with-ai-js","defaultUrl":"https://build-with-ai-js.web.app","appId":"1:526849588450:web:c8e88bb20a2258e300b2bb","type":"DEFAULT_SITE"}]}
[debug] [2024-05-03T17:08:09.730Z] >>> [apiv2][query] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js/webApps/1:526849588450:web:c8e88bb20a2258e300b2bb/config [none]
[debug] [2024-05-03T17:08:10.954Z] <<< [apiv2][status] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js/webApps/1:526849588450:web:c8e88bb20a2258e300b2bb/config 200
[debug] [2024-05-03T17:08:10.954Z] <<< [apiv2][body] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js/webApps/1:526849588450:web:c8e88bb20a2258e300b2bb/config {"projectId":"build-with-ai-js","appId":"1:526849588450:web:c8e88bb20a2258e300b2bb","storageBucket":"build-with-ai-js.appspot.com","apiKey":"AIzaSyCnqYU9dT3OLUagUsPrR1gwQ7K3O3HnKfU","authDomain":"build-with-ai-js.firebaseapp.com","messagingSenderId":"526849588450","measurementId":"G-JRFSMMKSRS"}
[debug] [2024-05-03T17:08:10.961Z] >>> [apiv2][query] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js [none]
[debug] [2024-05-03T17:08:11.569Z] <<< [apiv2][status] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js 200
[debug] [2024-05-03T17:08:11.569Z] <<< [apiv2][body] GET https://firebase.googleapis.com/v1beta1/projects/build-with-ai-js {"projectId":"build-with-ai-js","projectNumber":"526849588450","displayName":"build-with-ai-js","name":"projects/build-with-ai-js","resources":{"hostingSite":"build-with-ai-js"},"state":"ACTIVE","etag":"1_e4b279f8-da98-4aa3-98bb-56253b503885"}
[info] i  hosting[build-with-ai-js]: Serving hosting files from: frontend/dist {"metadata":{"emulator":{"name":"hosting"},"message":"Serving hosting files from: \u001b[1mfrontend/dist\u001b[22m"}}
[info] ✔  hosting[build-with-ai-js]: Local server: http://127.0.0.1:5000 {"metadata":{"emulator":{"name":"hosting"},"message":"Local server: \u001b[4m\u001b[1mhttp://127.0.0.1:5000\u001b[22m\u001b[24m"}}
[info] i  ui: downloading ui-v1.11.8.zip... {"metadata":{"emulator":{"name":"ui"},"message":"downloading ui-v1.11.8.zip..."}}
[debug] [2024-05-03T17:08:11.589Z] >>> [apiv2][query] GET https://storage.googleapis.com/firebase-preview-drop/emulator/ui-v1.11.8.zip 
[debug] [2024-05-03T17:08:11.913Z] <<< [apiv2][status] GET https://storage.googleapis.com/firebase-preview-drop/emulator/ui-v1.11.8.zip 200
[debug] [2024-05-03T17:08:11.913Z] <<< [apiv2][body] GET https://storage.googleapis.com/firebase-preview-drop/emulator/ui-v1.11.8.zip [stream]
[debug] [2024-05-03T17:08:12.344Z] Data is 3523907
[debug] [2024-05-03T17:08:12.345Z] [unzip] Entry: client/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:08:12.345Z] [unzip] Processing entry: client/
[debug] [2024-05-03T17:08:12.345Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/
[debug] [2024-05-03T17:08:12.345Z] [unzip] Entry: client/favicon.ico (compressed_size=2497 bytes, uncompressed_size=7406 bytes)
[debug] [2024-05-03T17:08:12.345Z] [unzip] Processing entry: client/favicon.ico
[debug] [2024-05-03T17:08:12.345Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client
[debug] [2024-05-03T17:08:12.345Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/favicon.ico
[debug] [2024-05-03T17:08:12.346Z] [unzip] Entry: client/apple-touch-icon.png (compressed_size=7231 bytes, uncompressed_size=7367 bytes)
[debug] [2024-05-03T17:08:12.346Z] [unzip] Processing entry: client/apple-touch-icon.png
[debug] [2024-05-03T17:08:12.346Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client
[debug] [2024-05-03T17:08:12.347Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/apple-touch-icon.png
[debug] [2024-05-03T17:08:12.347Z] [unzip] Entry: client/android-chrome-512x512.png (compressed_size=16987 bytes, uncompressed_size=18186 bytes)
[debug] [2024-05-03T17:08:12.347Z] [unzip] Processing entry: client/android-chrome-512x512.png
[debug] [2024-05-03T17:08:12.347Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client
[debug] [2024-05-03T17:08:12.347Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/android-chrome-512x512.png
[debug] [2024-05-03T17:08:12.348Z] [unzip] Entry: client/assets/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:08:12.348Z] [unzip] Processing entry: client/assets/
[debug] [2024-05-03T17:08:12.348Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/
[debug] [2024-05-03T17:08:12.348Z] [unzip] Entry: client/assets/extensions/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:08:12.348Z] [unzip] Processing entry: client/assets/extensions/
[debug] [2024-05-03T17:08:12.349Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/extensions/
[debug] [2024-05-03T17:08:12.349Z] [unzip] Entry: client/assets/extensions/default-extension.png (compressed_size=1646 bytes, uncompressed_size=1657 bytes)
[debug] [2024-05-03T17:08:12.349Z] [unzip] Processing entry: client/assets/extensions/default-extension.png
[debug] [2024-05-03T17:08:12.349Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/extensions
[debug] [2024-05-03T17:08:12.349Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/extensions/default-extension.png
[debug] [2024-05-03T17:08:12.349Z] [unzip] Entry: client/assets/index-Z4-ilXvq.js.map (compressed_size=2229704 bytes, uncompressed_size=9599487 bytes)
[debug] [2024-05-03T17:08:12.350Z] [unzip] Processing entry: client/assets/index-Z4-ilXvq.js.map
[debug] [2024-05-03T17:08:12.350Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets
[debug] [2024-05-03T17:08:12.350Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/index-Z4-ilXvq.js.map
[debug] [2024-05-03T17:08:12.413Z] [unzip] Entry: client/assets/provider-icons/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:08:12.413Z] [unzip] Processing entry: client/assets/provider-icons/
[debug] [2024-05-03T17:08:12.413Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons/
[debug] [2024-05-03T17:08:12.413Z] [unzip] Entry: client/assets/provider-icons/auth_service_oidc.svg (compressed_size=414 bytes, uncompressed_size=858 bytes)
[debug] [2024-05-03T17:08:12.414Z] [unzip] Processing entry: client/assets/provider-icons/auth_service_oidc.svg
[debug] [2024-05-03T17:08:12.414Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons
[debug] [2024-05-03T17:08:12.414Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons/auth_service_oidc.svg
[debug] [2024-05-03T17:08:12.415Z] [unzip] Entry: client/assets/provider-icons/auth_service_yahoo.svg (compressed_size=577 bytes, uncompressed_size=1182 bytes)
[debug] [2024-05-03T17:08:12.415Z] [unzip] Processing entry: client/assets/provider-icons/auth_service_yahoo.svg
[debug] [2024-05-03T17:08:12.415Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons
[debug] [2024-05-03T17:08:12.415Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons/auth_service_yahoo.svg
[debug] [2024-05-03T17:08:12.415Z] [unzip] Entry: client/assets/provider-icons/auth_service_phone.svg (compressed_size=261 bytes, uncompressed_size=414 bytes)
[debug] [2024-05-03T17:08:12.416Z] [unzip] Processing entry: client/assets/provider-icons/auth_service_phone.svg
[debug] [2024-05-03T17:08:12.416Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons
[debug] [2024-05-03T17:08:12.416Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons/auth_service_phone.svg
[debug] [2024-05-03T17:08:12.416Z] [unzip] Entry: client/assets/provider-icons/auth_service_saml.svg (compressed_size=575 bytes, uncompressed_size=1226 bytes)
[debug] [2024-05-03T17:08:12.416Z] [unzip] Processing entry: client/assets/provider-icons/auth_service_saml.svg
[debug] [2024-05-03T17:08:12.417Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons
[debug] [2024-05-03T17:08:12.417Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons/auth_service_saml.svg
[debug] [2024-05-03T17:08:12.417Z] [unzip] Entry: client/assets/provider-icons/auth_service_mslive.svg (compressed_size=203 bytes, uncompressed_size=378 bytes)
[debug] [2024-05-03T17:08:12.417Z] [unzip] Processing entry: client/assets/provider-icons/auth_service_mslive.svg
[debug] [2024-05-03T17:08:12.418Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons
[debug] [2024-05-03T17:08:12.418Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons/auth_service_mslive.svg
[debug] [2024-05-03T17:08:12.418Z] [unzip] Entry: client/assets/provider-icons/auth_service_facebook.svg (compressed_size=289 bytes, uncompressed_size=457 bytes)
[debug] [2024-05-03T17:08:12.418Z] [unzip] Processing entry: client/assets/provider-icons/auth_service_facebook.svg
[debug] [2024-05-03T17:08:12.419Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons
[debug] [2024-05-03T17:08:12.419Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons/auth_service_facebook.svg
[debug] [2024-05-03T17:08:12.419Z] [unzip] Entry: client/assets/provider-icons/auth_service_play_games.svg (compressed_size=565 bytes, uncompressed_size=1173 bytes)
[debug] [2024-05-03T17:08:12.419Z] [unzip] Processing entry: client/assets/provider-icons/auth_service_play_games.svg
[debug] [2024-05-03T17:08:12.420Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons
[debug] [2024-05-03T17:08:12.420Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons/auth_service_play_games.svg
[debug] [2024-05-03T17:08:12.420Z] [unzip] Entry: client/assets/provider-icons/auth_service_github.svg (compressed_size=466 bytes, uncompressed_size=838 bytes)
[debug] [2024-05-03T17:08:12.420Z] [unzip] Processing entry: client/assets/provider-icons/auth_service_github.svg
[debug] [2024-05-03T17:08:12.420Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons
[debug] [2024-05-03T17:08:12.421Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons/auth_service_github.svg
[debug] [2024-05-03T17:08:12.421Z] [unzip] Entry: client/assets/provider-icons/auth_service_apple.svg (compressed_size=230 bytes, uncompressed_size=334 bytes)
[debug] [2024-05-03T17:08:12.421Z] [unzip] Processing entry: client/assets/provider-icons/auth_service_apple.svg
[debug] [2024-05-03T17:08:12.421Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons
[debug] [2024-05-03T17:08:12.421Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons/auth_service_apple.svg
[debug] [2024-05-03T17:08:12.422Z] [unzip] Entry: client/assets/provider-icons/auth_service_google.svg (compressed_size=409 bytes, uncompressed_size=720 bytes)
[debug] [2024-05-03T17:08:12.422Z] [unzip] Processing entry: client/assets/provider-icons/auth_service_google.svg
[debug] [2024-05-03T17:08:12.422Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons
[debug] [2024-05-03T17:08:12.422Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons/auth_service_google.svg
[debug] [2024-05-03T17:08:12.423Z] [unzip] Entry: client/assets/provider-icons/auth_service_email.svg (compressed_size=228 bytes, uncompressed_size=326 bytes)
[debug] [2024-05-03T17:08:12.423Z] [unzip] Processing entry: client/assets/provider-icons/auth_service_email.svg
[debug] [2024-05-03T17:08:12.423Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons
[debug] [2024-05-03T17:08:12.423Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons/auth_service_email.svg
[debug] [2024-05-03T17:08:12.424Z] [unzip] Entry: client/assets/provider-icons/auth_service_twitter.svg (compressed_size=444 bytes, uncompressed_size=751 bytes)
[debug] [2024-05-03T17:08:12.424Z] [unzip] Processing entry: client/assets/provider-icons/auth_service_twitter.svg
[debug] [2024-05-03T17:08:12.424Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons
[debug] [2024-05-03T17:08:12.424Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons/auth_service_twitter.svg
[debug] [2024-05-03T17:08:12.425Z] [unzip] Entry: client/assets/provider-icons/auth_service_game_center.svg (compressed_size=991 bytes, uncompressed_size=3921 bytes)
[debug] [2024-05-03T17:08:12.425Z] [unzip] Processing entry: client/assets/provider-icons/auth_service_game_center.svg
[debug] [2024-05-03T17:08:12.425Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons
[debug] [2024-05-03T17:08:12.425Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/provider-icons/auth_service_game_center.svg
[debug] [2024-05-03T17:08:12.426Z] [unzip] Entry: client/assets/img/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:08:12.426Z] [unzip] Processing entry: client/assets/img/
[debug] [2024-05-03T17:08:12.426Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/img/
[debug] [2024-05-03T17:08:12.426Z] [unzip] Entry: client/assets/img/database.png (compressed_size=29449 bytes, uncompressed_size=29988 bytes)
[debug] [2024-05-03T17:08:12.426Z] [unzip] Processing entry: client/assets/img/database.png
[debug] [2024-05-03T17:08:12.426Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/img
[debug] [2024-05-03T17:08:12.427Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/img/database.png
[debug] [2024-05-03T17:08:12.427Z] [unzip] Entry: client/assets/index-Cj5I7867.css (compressed_size=35786 bytes, uncompressed_size=297937 bytes)
[debug] [2024-05-03T17:08:12.427Z] [unzip] Processing entry: client/assets/index-Cj5I7867.css
[debug] [2024-05-03T17:08:12.427Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets
[debug] [2024-05-03T17:08:12.428Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/index-Cj5I7867.css
[debug] [2024-05-03T17:08:12.430Z] [unzip] Entry: client/assets/index-Z4-ilXvq.js (compressed_size=563876 bytes, uncompressed_size=2021818 bytes)
[debug] [2024-05-03T17:08:12.430Z] [unzip] Processing entry: client/assets/index-Z4-ilXvq.js
[debug] [2024-05-03T17:08:12.430Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets
[debug] [2024-05-03T17:08:12.430Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/assets/index-Z4-ilXvq.js
[debug] [2024-05-03T17:08:12.444Z] [unzip] Entry: client/safari-pinned-tab.svg (compressed_size=838 bytes, uncompressed_size=1504 bytes)
[debug] [2024-05-03T17:08:12.445Z] [unzip] Processing entry: client/safari-pinned-tab.svg
[debug] [2024-05-03T17:08:12.445Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client
[debug] [2024-05-03T17:08:12.445Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/safari-pinned-tab.svg
[debug] [2024-05-03T17:08:12.445Z] [unzip] Entry: client/mstile-150x150.png (compressed_size=5406 bytes, uncompressed_size=5723 bytes)
[debug] [2024-05-03T17:08:12.446Z] [unzip] Processing entry: client/mstile-150x150.png
[debug] [2024-05-03T17:08:12.446Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client
[debug] [2024-05-03T17:08:12.446Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/mstile-150x150.png
[debug] [2024-05-03T17:08:12.446Z] [unzip] Entry: client/browserconfig.xml (compressed_size=491 bytes, uncompressed_size=822 bytes)
[debug] [2024-05-03T17:08:12.446Z] [unzip] Processing entry: client/browserconfig.xml
[debug] [2024-05-03T17:08:12.446Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client
[debug] [2024-05-03T17:08:12.447Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/browserconfig.xml
[debug] [2024-05-03T17:08:12.447Z] [unzip] Entry: client/robots.txt (compressed_size=26 bytes, uncompressed_size=26 bytes)
[debug] [2024-05-03T17:08:12.447Z] [unzip] Processing entry: client/robots.txt
[debug] [2024-05-03T17:08:12.447Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client
[debug] [2024-05-03T17:08:12.448Z] [unzip] Writing file: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/robots.txt
[debug] [2024-05-03T17:08:12.448Z] [unzip] Entry: client/index.html (compressed_size=1365 bytes, uncompressed_size=3071 bytes)
[debug] [2024-05-03T17:08:12.449Z] [unzip] Processing entry: client/index.html
[debug] [2024-05-03T17:08:12.449Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client
[debug] [2024-05-03T17:08:12.449Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/index.html
[debug] [2024-05-03T17:08:12.449Z] [unzip] Entry: client/favicon-16x16.png (compressed_size=757 bytes, uncompressed_size=777 bytes)
[debug] [2024-05-03T17:08:12.449Z] [unzip] Processing entry: client/favicon-16x16.png
[debug] [2024-05-03T17:08:12.449Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client
[debug] [2024-05-03T17:08:12.450Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/favicon-16x16.png
[debug] [2024-05-03T17:08:12.450Z] [unzip] Entry: client/manifest.json (compressed_size=246 bytes, uncompressed_size=551 bytes)
[debug] [2024-05-03T17:08:12.450Z] [unzip] Processing entry: client/manifest.json
[debug] [2024-05-03T17:08:12.450Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client
[debug] [2024-05-03T17:08:12.451Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/manifest.json
[debug] [2024-05-03T17:08:12.451Z] [unzip] Entry: client/favicon-32x32.png (compressed_size=1175 bytes, uncompressed_size=1175 bytes)
[debug] [2024-05-03T17:08:12.451Z] [unzip] Processing entry: client/favicon-32x32.png
[debug] [2024-05-03T17:08:12.451Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client
[debug] [2024-05-03T17:08:12.452Z] [unzip] Writing file: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/favicon-32x32.png
[debug] [2024-05-03T17:08:12.452Z] [unzip] Entry: client/android-chrome-192x192.png (compressed_size=7602 bytes, uncompressed_size=7834 bytes)
[debug] [2024-05-03T17:08:12.452Z] [unzip] Processing entry: client/android-chrome-192x192.png
[debug] [2024-05-03T17:08:12.452Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client
[debug] [2024-05-03T17:08:12.452Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/client/android-chrome-192x192.png
[debug] [2024-05-03T17:08:12.453Z] [unzip] Entry: server/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:08:12.453Z] [unzip] Processing entry: server/
[debug] [2024-05-03T17:08:12.453Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/server/
[debug] [2024-05-03T17:08:12.453Z] [unzip] Entry: server/server.mjs (compressed_size=311497 bytes, uncompressed_size=1147307 bytes)
[debug] [2024-05-03T17:08:12.453Z] [unzip] Processing entry: server/server.mjs
[debug] [2024-05-03T17:08:12.453Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/server
[debug] [2024-05-03T17:08:12.454Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/server/server.mjs
[debug] [2024-05-03T17:08:12.460Z] [unzip] Entry: server/assets/ (compressed_size=0 bytes, uncompressed_size=0 bytes)
[debug] [2024-05-03T17:08:12.460Z] [unzip] Processing entry: server/assets/
[debug] [2024-05-03T17:08:12.460Z] [unzip] mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/server/assets/
[debug] [2024-05-03T17:08:12.461Z] [unzip] Entry: server/assets/multipart-parser-n20ATYm_.mjs.map (compressed_size=4790 bytes, uncompressed_size=17920 bytes)
[debug] [2024-05-03T17:08:12.461Z] [unzip] Processing entry: server/assets/multipart-parser-n20ATYm_.mjs.map
[debug] [2024-05-03T17:08:12.461Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/server/assets
[debug] [2024-05-03T17:08:12.461Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/server/assets/multipart-parser-n20ATYm_.mjs.map
[debug] [2024-05-03T17:08:12.462Z] [unzip] Entry: server/assets/multipart-parser-n20ATYm_.mjs (compressed_size=2625 bytes, uncompressed_size=10428 bytes)
[debug] [2024-05-03T17:08:12.462Z] [unzip] Processing entry: server/assets/multipart-parser-n20ATYm_.mjs
[debug] [2024-05-03T17:08:12.462Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/server/assets
[debug] [2024-05-03T17:08:12.462Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/server/assets/multipart-parser-n20ATYm_.mjs
[debug] [2024-05-03T17:08:12.463Z] [unzip] Entry: server/server.mjs.map (compressed_size=286219 bytes, uncompressed_size=1310517 bytes)
[debug] [2024-05-03T17:08:12.463Z] [unzip] Processing entry: server/server.mjs.map
[debug] [2024-05-03T17:08:12.463Z] [unzip] else mkdir: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/server
[debug] [2024-05-03T17:08:12.463Z] [unzip] deflating: /home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/server/server.mjs.map
[info] i  ui: Removing outdated emulator files: ui-v1.11.7 {"metadata":{"emulator":{"name":"ui"},"message":"Removing outdated emulator files: ui-v1.11.7"}}
[info] i  ui: Removing outdated emulator files: ui-v1.11.7.zip {"metadata":{"emulator":{"name":"ui"},"message":"Removing outdated emulator files: ui-v1.11.7.zip"}}
[debug] [2024-05-03T17:08:12.478Z] Ignoring unsupported arg: auto_download {"metadata":{"emulator":{"name":"ui"},"message":"Ignoring unsupported arg: auto_download"}}
[debug] [2024-05-03T17:08:12.479Z] Ignoring unsupported arg: port {"metadata":{"emulator":{"name":"ui"},"message":"Ignoring unsupported arg: port"}}
[debug] [2024-05-03T17:08:12.479Z] Starting Emulator UI with command {"binary":"node","args":["/home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/server/server.mjs"],"optionalArgs":[],"joinArgs":false,"shell":false} {"metadata":{"emulator":{"name":"ui"},"message":"Starting Emulator UI with command {\"binary\":\"node\",\"args\":[\"/home/edupsousa/.cache/firebase/emulators/ui-v1.11.8/server/server.mjs\"],\"optionalArgs\":[],\"joinArgs\":false,\"shell\":false}"}}
[info] i  ui: Emulator UI logging to ui-debug.log {"metadata":{"emulator":{"name":"ui"},"message":"Emulator UI logging to \u001b[1mui-debug.log\u001b[22m"}}
[debug] [2024-05-03T17:08:12.596Z] Web / API server started at 127.0.0.1:4000
 {"metadata":{"emulator":{"name":"ui"},"message":"Web / API server started at 127.0.0.1:4000\n"}}
[debug] [2024-05-03T17:08:12.596Z] Web / API server started at ::1:4000
 {"metadata":{"emulator":{"name":"ui"},"message":"Web / API server started at ::1:4000\n"}}
[debug] [2024-05-03T17:08:12.687Z] [Extensions] Connecting Extensions emulator, this is a noop.
[info] i  functions: Watching "/home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions" for Cloud Functions... {"metadata":{"emulator":{"name":"functions"},"message":"Watching \"/home/edupsousa/.cache/firebase/extensions/googlecloud/firestore-multimodal-genai@1.0.0/functions\" for Cloud Functions..."}}
[info] ✔  functions: Loaded functions definitions from source: generateOnCall, generateText. {"metadata":{"emulator":{"name":"functions"},"message":"Loaded functions definitions from source: generateOnCall, generateText."}}
[info] ✔  functions[southamerica-east1-ext-firestore-multimodal-genai-generateOnCall]: http function initialized (http://127.0.0.1:5001/build-with-ai-js/southamerica-east1/ext-firestore-multimodal-genai-generateOnCall). {"metadata":{"emulator":{"name":"functions"},"message":"\u001b[1mhttp\u001b[22m function initialized (http://127.0.0.1:5001/build-with-ai-js/southamerica-east1/ext-firestore-multimodal-genai-generateOnCall)."}}
[debug] [2024-05-03T17:08:12.690Z] addFirestoreTrigger "{\"eventTrigger\":{\"eventType\":\"providers/cloud.firestore/eventTypes/document.write\",\"resource\":\"projects/build-with-ai-js/databases/(default)/documents/generate/{summaryId}\",\"service\":\"firestore.googleapis.com\"}}"
[debug] [2024-05-03T17:08:12.691Z] >>> [apiv2][query] PUT http://127.0.0.1:8080/emulator/v1/projects/build-with-ai-js/triggers/southamerica-east1-ext-firestore-multimodal-genai-generateText-0 [none]
[debug] [2024-05-03T17:08:12.691Z] >>> [apiv2][body] PUT http://127.0.0.1:8080/emulator/v1/projects/build-with-ai-js/triggers/southamerica-east1-ext-firestore-multimodal-genai-generateText-0 "{\"eventTrigger\":{\"eventType\":\"providers/cloud.firestore/eventTypes/document.write\",\"resource\":\"projects/build-with-ai-js/databases/(default)/documents/generate/{summaryId}\",\"service\":\"firestore.googleapis.com\"}}"
[debug] [2024-05-03T17:08:12.710Z] May 03, 2024 2:08:12 PM io.gapi.emulators.netty.HttpVersionRoutingHandler channelRead
INFO: Detected non-HTTP/2 connection.
 {"metadata":{"emulator":{"name":"firestore"},"message":"May 03, 2024 2:08:12 PM io.gapi.emulators.netty.HttpVersionRoutingHandler channelRead\nINFO: Detected non-HTTP/2 connection.\n"}}
[debug] [2024-05-03T17:08:13.028Z] May 03, 2024 2:08:13 PM io.gapi.emulators.netty.HttpVersionRoutingHandler channelRead
INFO: Detected HTTP/2 connection.
 {"metadata":{"emulator":{"name":"firestore"},"message":"May 03, 2024 2:08:13 PM io.gapi.emulators.netty.HttpVersionRoutingHandler channelRead\nINFO: Detected HTTP/2 connection.\n"}}
[debug] [2024-05-03T17:08:13.863Z] <<< [apiv2][status] PUT http://127.0.0.1:8080/emulator/v1/projects/build-with-ai-js/triggers/southamerica-east1-ext-firestore-multimodal-genai-generateText-0 200
[debug] [2024-05-03T17:08:13.863Z] <<< [apiv2][body] PUT http://127.0.0.1:8080/emulator/v1/projects/build-with-ai-js/triggers/southamerica-east1-ext-firestore-multimodal-genai-generateText-0 {}
[info] ✔  functions[southamerica-east1-ext-firestore-multimodal-genai-generateText]: firestore function initialized. {"metadata":{"emulator":{"name":"functions"},"message":"\u001b[1mfirestore\u001b[22m function initialized."}}
[info] 
┌─────────────────────────────────────────────────────────────┐
│ ✔  All emulators ready! It is now safe to connect your app. │
│ i  View Emulator UI at http://127.0.0.1:4000/               │
└─────────────────────────────────────────────────────────────┘

┌────────────────┬────────────────┬──────────────────────────────────┐
│ Emulator       │ Host:Port      │ View in Emulator UI              │
├────────────────┼────────────────┼──────────────────────────────────┤
│ Authentication │ 127.0.0.1:9099 │ http://127.0.0.1:4000/auth       │
├────────────────┼────────────────┼──────────────────────────────────┤
│ Functions      │ 127.0.0.1:5001 │ http://127.0.0.1:4000/functions  │
├────────────────┼────────────────┼──────────────────────────────────┤
│ Firestore      │ 127.0.0.1:8080 │ http://127.0.0.1:4000/firestore  │
├────────────────┼────────────────┼──────────────────────────────────┤
│ Hosting        │ 127.0.0.1:5000 │ n/a                              │
├────────────────┼────────────────┼──────────────────────────────────┤
│ Extensions     │ 127.0.0.1:5001 │ http://127.0.0.1:4000/extensions │
└────────────────┴────────────────┴──────────────────────────────────┘
  Emulator Hub running at 127.0.0.1:4400
  Other reserved ports: 4500, 9150
┌────────────────────────────┬──────────────────────────────────────────────┬─────────────────────────────────────────────────────────────┐
│ Extension Instance Name    │ Extension Ref                                │ View in Emulator UI                                         │
├────────────────────────────┼──────────────────────────────────────────────┼─────────────────────────────────────────────────────────────┤
│ firestore-multimodal-genai │ googlecloud/firestore-multimodal-genai@1.0.0 │ http://127.0.0.1:4000/extensions/firestore-multimodal-genai │
└────────────────────────────┴──────────────────────────────────────────────┴─────────────────────────────────────────────────────────────┘
Issues? Report them at https://github.com/firebase/firebase-tools/issues and attach the *-debug.log files.
 
[debug] [2024-05-03T17:10:17.735Z] >>> [apiv2][query] POST http://127.0.0.1:5001/functions/projects/build-with-ai-js/trigger_multicast [none]
[debug] [2024-05-03T17:10:17.735Z] >>> [apiv2][body] POST http://127.0.0.1:5001/functions/projects/build-with-ai-js/trigger_multicast {"eventId":"3a603576-7728-4223-8d09-8c4b6e05ed1a","eventType":"providers/firebase.auth/eventTypes/user.create","resource":{"name":"projects/build-with-ai-js","service":"firebaseauth.googleapis.com"},"params":{},"timestamp":"2024-05-03T17:10:17.734Z","data":{"uid":"c49IyMXj2eAwWPg2kI3hmkFC6sjT","email":"peach.otter.736@example.com","emailVerified":true,"displayName":"Peach Otter","metadata":{"creationTime":"2024-05-03T17:10:17.733Z","lastSignInTime":"2024-05-03T17:10:17.733Z"},"customClaims":{},"providerData":[{"providerId":"google.com","rawId":"9061729188186397895356987699780039075853","federatedId":"9061729188186397895356987699780039075853","displayName":"Peach Otter","email":"peach.otter.736@example.com","screenName":"otter_peach"}]}}
[debug] [2024-05-03T17:10:17.747Z] <<< [apiv2][status] POST http://127.0.0.1:5001/functions/projects/build-with-ai-js/trigger_multicast 200
[debug] [2024-05-03T17:10:17.747Z] <<< [apiv2][body] POST http://127.0.0.1:5001/functions/projects/build-with-ai-js/trigger_multicast {"status":"multicast_acknowledged"}
